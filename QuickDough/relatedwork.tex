\section{Related Work}\label{sec:relatedwork}
Despite their promising performance advantage, the relatively low design productivity of developing
FPGA applications remains a major obstacle that hinders widespread adoption of FPGAs as commodity
computing devices. To address this problem, the design of QuickDough was inspired by the recent success in HLS tools.
It also took advantage of modern FPGAs' capabilities to allow for an additional overlay architecture
be employed for productivity sake.

\subsection{High-Level Synthesis}
To bridge the design productivity gap between software and hardware application development, many researchers have turned to the use of HLS techniques \cite{cong2011high}.
By raising the abstraction level of the physical hardware, HLS allows designers to express hardware designs using familiar high-level, software-like description languages such as C, Java, or Python \cite{cardoso2010compiling,Canis:2011:LHS:1950413.1950423}.
The low-level hardware implementations are then left to the tools to synthesize and optimize.
Indeed, with decades of research, some early results in HLS have already found their ways into FPGA vendors' commercial tools in recent years \cite{chen2005xpilot, zhang2008autopilot, VivadoHLS}.

Unfortunately, when considering the overall design productivity of developing hybrid software-gateware applications, the raised abstraction provided by HLS is only addressing part of the problem.
While the high-level abstraction makes expressing complex functionalities as FPGA gateware easier, the lengthy low-level compilation time spent in synthesis, mapping, placing and routing remains a bottleneck to the overall design productivity for an application designer.
Such long compilation time is particularly challenging for novice designers who are accustomed to the high speed of software compilation.
Most importantly, it is significantly impacting the possible compile-debug-edit cycle achievable per day by a designer, negatively impacting the productivity of the designer.

\subsection{Overlay Architectures}
To improve the speed of low-level implementation tools, researchers have explored various approaches over the past decades.
Inspired by application specific integrated circuit (ASIC) design flows, researchers and vendors have developed modular design flow and explored the use of pre-compiled hard macros \cite{lavin2010using,lavin2011} as implementation library.
In addition, researchers have also exploited the use of dynamic partial reconfiguration capabilities in FPGAs \cite{Frangieh2010} as a way to improve productivity.
In recent years, there has been an increased interest in applying the concept of \emph{overlay architectures} as a way to address this productivity challenge.  


An overlay architecture is a virtual intermediate architecture that is overlaid on top of the physical configurable fabric of an FPGA.  They are employed during the FPGA application implementation process for purposes such as to improve portability, security, and also productivity.
%Depending on the design goal, overlays have manifested in various forms, including HDL models, pre-synthesized or pre-implemented coarse-grained circuits, or even arrays of processing elements with various granularity. 

One of the most familiar categories of overlay consists of virtual FPGAs \cite{zuma2013carl,Grant2011Malibu,Coole2010Intermediate,Koch2013CI}. They are built either virtually or physically on top of off-the-shelf FPGA devices and typically feature coarser configuration granularity than the physical device.
Similar to virtual machines running on a typical computer, such virtual FPGA provides an additional layer that improves application portability and security.
Furthermore, because of the coarser-grained configurable fabric, implementing designs on such overlay is relatively easier than on a fine-grained device.
However, the additional layer imposes restrictions on the underlying fabrics' capability and usually results in moderate hardware overhead and timing degradation.

Another category of overlay architecture commonly employed is in the form of coarse-grained reconfigurable arrays (CGRAs).
The use of CGRAs provides unique advantages of performance especially for compute intensive applications as demonstrated by numerous ASIC CGRAs \cite{tessier2001reconfigurable} \cite{compton2002reconfigurable}.
Indeed, CGRAs on FPGA and ASIC have many similarities in terms of the scheduling algorithm and array structure.
However, they have quite different trade-offs in terms of configuration flexibility, overhead and performance.
In a nutshell, CGRAs on ASIC emphasize more on configuration capability to cover more applications, while FPGAs' inherent programmability greatly alleviates the concern.
Instead, CGRAs on FPGA may take advantage of the configurability of the underlying fabric to allow more intensive customization tailored to the target application.

The authors in \cite{kissler2006dynamically} developed WPPA (weakly programmable processor array), a VLIW architecture based parameterizable CGRA overlay. It featured an interconnection wrapper unit for each processing element (PE) that could be used for dynamic CGRAs topology customization. Unfortunately, programming and compilation on WPPA were not presented. The authors in \cite{ferreira2011fpga} proposed a heterogeneous CGRA overlay with a global multi-stage interconnection on FPGA. Compiling applications onto the overlay took only milliseconds for smaller DFGs. However, the global multi-stage interconnection required multiple stages for communication between each pair of PEs and resulted in either low implementation frequency or large communication latency in terms of cycles. In addition, there was no intermediate storage except the pipeline registers in the CGRA and it limited the performance of the operation scheduling.
In \cite{shukla2006quku}, a customized CGRA overlay called QUKU was developed for DSP algorithms. It had two-level configuration capability, while the low-speed configuration was used for operator reuse within an application and high-speed reconfiguration was used for optimization between different applications. Nevertheless, the hardware infrastructure was consist of simple operation elements which can only be adapted to a few specified DSP algorithms.
The authors in \cite{capalijia2013pipelined} built a more generic high speed mesh CGRA overlay using the elastic pipeline technique to achieve the maximum throughput. It adopted a data-driven execution flow and was suitable for smaller pipelined DFG execution, while it would be difficult to handle applications with random IO access. 

In general, previous CGRA overlays have demonstrated the promising performance acceleration capability for compute intensive applications. They typically take DFG as design entry and focus on hardware infrastructure design as well as corresponding mapping and scheduling. However, they are still lack of consideration on proper loop unrolling for DFG generation, on-chip buffering, the communication with host and even end-to-end performance which are essential for FPGA accelerator design especially from a HW/SW co-design engineer's perspective. 


Finally, a third category of overlay features soft-processor-like architectures with high degree of
control and data parallelism suitable for FPGA accelerations.  For example, in the work of MARC
\cite{Lebedev2010}, a many-core overlay with customizable data path was proposed.  Similarly, a
GPU-like overlay was proposed in \cite{Jeffrey2011potential}.


In this work, we opted to utilize a fully pipelined synchronous soft coarse-grained reconfigurable
array (SCGRA) as an overlay to facilitate rapid FPGA accelerator generation in a hybrid CPU-FPGA
system. Compared to previously proposed CGRAs, our overlay is designed to be \emph{soft} as the size,
processing element designs, as well as the interconnect topologies may all be customized as needed
providing just enough resource for an application specifically. Moreover, the design of our overlay
is regular and design parameters such as loop unrolling factor and overlay size have
relatively predictable influence on the overlay performance and overhead, which makes the
customization much easier and more efficient. Finally, it also takes advantage of the large number
of on-chip distributed memory on the FPGA for intermediate data storage and can handle large DFGs
with thousands of nodes. 

%On top of the above approaches, the use of \emph{overlays} in the form of HDL Model, pre-synthesized or pre-implemented coarse-grained reconfigurable circuits over the fine-grained FPGA devices, promises both to raise the abstraction level and reduce the compilation time.
%Recent years have seen a number of overlay designs being developed with granularities ranging from multi-processors to highly configurable logic arrays \cite{Lebedev2010,kissler2006dynamically,unnikrishnan2009application,Yiannacouras2009FPS,Guy2012VENICE,Jeffrey2011potential}. 

%% Not so much overlay, removed for clarity sake.
%Soft processors, which allow customization for target applications or application domains, have already been demonstrated to be efficient overlays on FPGA. A great number of work use embedded processors as FPGA overlays with micro-architecture parameters such as pipeline depth configurable \cite{Yiannacouras2007Exploration,microblaze,nios} and 


%instruction set architecture (ISA) customizable \cite{grad2009woolcano, }. 


%multi-processor overlay with both micro-architecture and interconnection customizable \cite{unnikrishnan2009application}, 

% vector processors overlay \cite{Guy2012VENICE,Yiannacouras2009FPS}


