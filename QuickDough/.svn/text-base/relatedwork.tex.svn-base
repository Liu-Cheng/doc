\section{Related Work}\label{sec:relatedwork}
To improve the productivity of FPGA designers, researchers have approached the problem both by increasing the abstraction level and reducing the compilation time.

In the first case, decades of research in FPGA high-level synthesis have already demonstrated their indispensible role in promoting FPGA design productivity \cite{cong2011high}. Numerous design languages and environments \cite{cardoso2010compiling} have been developed to allow designers to focus on high-level functionality instead of low-level implementation details. While high-level abstraction may help a designers express the desired functionality, the low-level compilation time spent on synthesis, mapping, placing and routing for FPGAs remains a major hindrances to designs' productivity. Researchers have approached the problem from many angles, such as through the use of pre-compiled hard macros \cite{lavin2011} in the tool flow, the use of a partial reconfiguration, and modular design flow \cite{Frangieh2010}. 

On top of the above approaches, overlays, which can be parametric HDL Model, pre-synthesized or pre-implemented coarse-grained reconfigurable circuits over the fine-grained FPGA devices, promise both to raise the abstraction level and reduce the compilation time. Thus great research efforts have been attracted over the years and a number of overlays have been proposed \cite{Lebedev2010,kissler2006dynamically,unnikrishnan2009application,Yiannacouras2009FPS,Guy2012VENICE,Jeffrey2011potential}. The granularity of these overlays ranges from multi-processors to highly configurable logic arrays. 

Soft processors, which allow customization from various angles for target applications or application domains, have already been demonstrated to be efficient overlays for implementing an application on FPGA. \cite{Yiannacouras2007Exploration},\cite{microblaze}, and \cite{nios} employ general processors as the overlay and mainly have micro-architecture parameters such as pipeline depth configurable. \cite{grad2009woolcano} uses general processor with custom instruction extension as overlay, but hardware implementation is required whenever new custom instructions are added. \cite{Kock2013CI} develops a fine-grain virtual FPGA overlay specially for custom instruction extension, which makes the custom instruction implementation portable and fast. \cite{Lebedev2010} has customized data path on a many-core overlay, it could support both the coarse-grain multi-thread parallelism and data-flow style fine-grain threading parallelism. \cite{unnikrishnan2009application} adopts a multi-processor overlay with both micro-architecture and interconnection customizable. \cite{Guy2012VENICE} and \cite {Yiannacouras2009FPS} develop reconfigurable vector processors as the FPGA overlay to cover larger domains of applications. \cite{Jeffrey2011potential} presented a GPU-Like overlay for portability and it could explore both the data-level parallelism and thread level parallelism. These processor level overlays typically approach the customization through instruction set extension or micro-architecture parameters tuning, and the application developers don't need much interaction with the low level hardware customization. Thus an application can be implemented rapidly, while the penalty is the hardware overhead and implementation frequency.    

\cite{zuma2013carl} and \cite{Grant2011Malibu} build fine-grain components and mixed-grain components as a virtual FPGA overlay over the off-the-shelf FPGA devices. The virtual FPGAs allow the designers to reuse the virtual bitstream which is compatible across different FPGA vendors and parts. Particularly, the virtual FPGA with coarse granularity of components could also decrease the compilation time. \cite{Coole2010Intermediate} developed a family of intermediate fabrics which fits well for data parallel circuit implementation and the compilation time is almost comparable to software compilation. Apparently, the virtual FPGA overlays are beneficial to improving the design productivity and portability, though they do result in moderate hardware overhead and timing degradation.   

Between the processor level overlays and virtual FPGA level overlays, CGRA overlays on FPGA have unique advantages of compromising hardware implementation and performance especially for compute intensive applications as demonstrated by numerous ASIC CGRAs \cite{tessier2001reconfigurable} \cite{compton2002reconfigurable}. CGRAs on FPGA and ASIC have many similarities in terms of the scheduling algorithm and array structure, however, they have quite different trade-off on configuration flexibility, overhead and performance. Basically, CGRAs on ASIC need to emphasize more on configuration capability to cover more applications, while FPGAs' inherent programmability greatly alleviate this concern. Accordingly, CGRAs on FPGA could accept more intensive customization while design productivity comes up as a new challenge. 

\cite{kissler2006dynamically} develops a VLIW architecture based parameterizable CGRA overlay called WPPA and provides an interconnection wrapper unit for each processing element to dynamically configure the topology of the CGRA. \cite{ferreira2011fpga} proposes an heterogeneous CGRA overlay with multi-stage interconnection on FPGA, and the compilation can be done in milliseconds. While the CGRA size is quite limited and the implementation frequency is low due to the multi-stage interconnection. \cite{shukla2006quku} develops a CGRA overlay named QUKU to improve reconfiguration speed for DSP algorithms. The experiments show that the CGRA overlay bridges the gap between soft processor and customized IP core. \cite{capalijia2013pipelined} builds an high speed mesh CGRA overlay using the elastic pipeline technique and achieves the maximum throughput. These CGRA overlay work typically take DFG as input and it is also possible to extract DFG during the software compilation. Thus the CGRA overlay helps to raise the abstraction level compared to conventional hardware design. Given the CGRA overlay architecture, the compilation doesn't involve any circuit optimization such as timing and pipelining at all and it makes the design accessible to an application developer without much hardware design experience. Especially, unlike the soft processor overlay and virtual FPGA overlay, \cite{capalijia2013pipelined} shows that the CGRA overlay doesn't have to compromise between the implementation frequency and design productivity as well as design portability. 

As demonstrated in previous CGRA work, one of the major motivations of using CGRA overlays is its promising performance acceleration capability for compute intensive applications. However, a complete accelerator design on a hybrid general purpose processor (GPP) + FPGA using CGRA overlay is still missing. In fact, communication between FPGA and GPP is expensive, it has significant impact on the overall performance acceleration and thus influence the design choices of the CGRA overlay as well. 

In this work, we opt to utilize a fully pipelined synchronous SCGRA as the overlay. Then we further implement it as an accelerator on Zedboard \cite{zedboard} which is a hybrid ARM + FPGA system. The accelerator now is configurable and is capable to handle all of our four full compute intensive applications with diverse data sets. With this SCGRA overlay based accelerator design method, an application can be implemented in a short time and the performance is competitive.

