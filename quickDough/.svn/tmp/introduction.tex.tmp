<<<<<<< .mine
\section{Introduction}\label{sec:introduction}
The use of FPGAs as compute accelerators has been demonstrated by numerous researchers as an effective solution to meet the performance requirement across many application domains.  However, despite years of research with numerous successful demonstrations, the use of FPGAs as computing devices remains a niche discipline that has yet to receive widespread adoption beyond highly skilled hardware engineers.  

Compared to a typical software development environment, developing applications to execute on FPGAs is a lengthy and tedious process.  While advancements in high level synthesis (HLS) tools have helped lower the barrier-to-entry for novel users \cite{cong2011high}, achieving the desired performance in the final design usually demands detailed low-level design engineering efforts such as retiming and pipelining that are foreign to many high-level application designers. Furthermore, unless the HLS tool can directly synthesize the target FPGA configuration, vendor's backend implementation tools must be employed for tasks such as floorplanning and placing-and-routing of the design.  Compared to software compilation, the run-time of such backend implementation tools is at least 2 to 3 orders of magnitude slower.  Spending several hours on place-and-route alone is not uncommon for a complex design targeting a state-of-the-art FPGA.  As a result, the number of compile-debug-edit cycle per day achievable is greatly limited, hindering the productivity of the designers especially during early development phases.

To address such productivity bottleneck, we propose a high-level synthesis methodology that utilizes a \emph{soft} coarse-grained reconfigurable array as an intermediate step to produce a final configurable bitstream directly from applications written in high-level languages.  Instead of synthesizing to circuits on the FPGAs, application compute kernels are extracted as dataflow graphs that are \emph{statically} scheduled to operate on the SCGRA.  The lengthy hardware implementation tool flow is thus reduced to an operation scheduling problem.  

Although the design and implementation of the SCRGA must rely on the conventional hardware design flow, only one instance of the SCGRA design is required per application or application domain.  Subsequent application development may then be accomplished rapidly by executing a simple scheduling algorithm.  Furthermore, the performance of the SCGRA can be carefully optimized by a separate experienced hardware engineering team.  Since the physical implementation of the SCGRA remains unchanged across applications or design iterations, the physical performance of the design can be guaranteed.  In this work, we have demonstrated an optimized SCGRA may execute at over 400 MHz on a Xilinx Virtex 6 FPGA, close to the advertised highest clock rate of the device.  When compared to a conventional design methodology using commercial HLS tools, an overall 5-34x improvement in end-to-end performance has been achieved across the benchmarked applications.





%The authors in \cite{colinheart} proposed to schedule DFG to a group of customized computation processing elements (CPE) while implementing the customized CPE array on FPGA for computation acceleration. They focused on the CPE array customization especially the interconnections of the array to achieve better performance and lower power consumption. However, customizing CPE array and implementing it whenever application changes is extremely time-consuming. Partial reconfiguration technique may alleviate the problem, but it will further bring the timing closure challenge due to the irregular global interconnection.


%In this paper, we borrow the concept taking CPE array as an intermediate layer and putting the HLL program to CPE array instead of RTL specification. Then we incorporate it with hardware implementation and propose a complete HLS method which goes through all the way from HLL program compiling to final bitstream generation on target FPGA. The proposed HLS method also takes CPE array as hardware infrastructure. The difference is that it employs a relatively determined and implementation-friendly CPE array for a group of applications instead of customized CPE array for each specific application. Since the CPE array is similar to the coarse grain reconfigurable array (CGRA) \cite{tessier2001reconfigurable} and still leaves kind for customization, we name it soft coarse grain reconfigurable array (SCGRA).


%The idea taking SCGRA as hardware infrastructure seems trivial, but it brings folded benefits to the HLS design method. On one hand, it allows us to pre-implement the SCGRA for a group or domain of applications. As long as the pre-implemented SCGRA can cover the target application, we can directly integrate the scheduling result into pre-implemented bitstream and have the application implemented without RTL compiling process. Consequently, the design productivity is promoted prominently. On the other hand, the SCGRA is well-defined and can be fully pipelined, so it can be implemented at almost extreme speed of the FPGA device. In this case, we can implement any applications supported by the SCGRA near full speed of the target FPGA device. Additionally, SCGRA based computation scheme also exhibits superiority on computation intensive applications. By combing both advantages in implementation frequency and computation efficiency, the proposed HLS method is able to provide the applications with high performance implementations.


The main contributions of this work can therefore be summarized as follows:
\begin{itemize}
\item A SCGRA based HLS methodology is proposed, which improves design productivity through bypassing the lengthy RTL compilation process.
\item A fully pipelined SCGRA is developed that executes at  almost full speed of the targeted FPGA device.
\item An efficient operation scheduling algorithm is implemented specially targeting the proposed fully pipelined SCGRA.
\end{itemize}

In the next section, related work is briefly introduced. In \secref{sec:methodology}, the proposed HLS design methodology will be elaborated.  In \secref{sec:scgra} the design of our high frequency SCGRA is presented. In \secref{sec:results}, we show the experimental results in terms of design efficiency, hardware implementation as well as performance.  Finally, we conclude this work in \secref{sec:conclusions}.

=======
\section{Introduction}\label{sec:introduction}
The use of FPGAs as compute accelerators has been demonstrated by numerous researchers as an effective solution to meet the performance requirement across many application domains.  However, despite years of research with numerous successful demonstrations, the use of FPGAs as computing devices remains a niche discipline that has yet to receive widespread adoption beyond highly skilled hardware engineers.  

Compared to a typical software development environment, developing applications to execute on FPGAs is a lengthy and tedious process.  While advancements in high level synthesis (HLS) tools have helped lower the barrier-to-entry for novel users, achieving the desired performance in the final design usually demands detailed low-level design engineering efforts such as retiming and pipelining that are foreign to many high-level application designers. Furthermore, unless the HLS tool can directly synthesize the target FPGA configuration, vendor's backend implementation tools must be employed for tasks such as floorplanning and placing-and-routing of the design.  Compared to software compilation, the run-time of such backend implementation tools is at least 2 to 3 orders of magnitude slower.  Spending several hours on place-and-route alone is not uncommon for a complex design targeting a state-of-the-art FPGA.  As a result, the number of compile-debug-edit cycle per day achievable is greatly limited, hindering the productivity of the designers especially during early development phases.

To address such productivity bottleneck, we propose a high-level synthesis methodology that utilizes a \emph{soft} coarse-grained reconfigurable array as an intermediate step to produce a final configurable bitstream directly from applications written in high-level languages.  Instead of synthesizing to circuits on the FPGAs, application compute kernels are extracted as dataflow graphs that are \emph{statically} scheduled to operate on the SCGRA.  The lengthy hardware implementation tool flow is thus reduced to an operation scheduling problem.  

Although the design and implementation of the SCRGA must rely on the conventional hardware design flow, only one instance of the SCGRA design is required per application or application domain.  Subsequent application development may then be accomplished rapidly by executing a simple scheduling algorithm.  Furthermore, the performance of the SCGRA can be carefully optimized by a separate experienced hardware engineering team.  Since the physical implementation of the SCGRA remains unchanged across applications or design iterations, the physical performance of the design can be guaranteed.  In this work, we have demonstrated an optimized SCGRA may execute at over 400 MHz on a Xilinx Virtex 6 FPGA, close to the advertised highest clock rate of the device.  When compared to a conventional design methodology using commercial HLS tools, an overall 5-34x improvement in end-to-end performance has been achieved across the benchmarked applications.





%The authors in \cite{colinheart} proposed to schedule DFG to a group of customized computation processing elements (CPE) while implementing the customized CPE array on FPGA for computation acceleration. They focused on the CPE array customization especially the interconnections of the array to achieve better performance and lower power consumption. However, customizing CPE array and implementing it whenever application changes is extremely time-consuming. Partial reconfiguration technique may alleviate the problem, but it will further bring the timing closure challenge due to the irregular global interconnection.


%In this paper, we borrow the concept taking CPE array as an intermediate layer and putting the HLL program to CPE array instead of RTL specification. Then we incorporate it with hardware implementation and propose a complete HLS method which goes through all the way from HLL program compiling to final bitstream generation on target FPGA. The proposed HLS method also takes CPE array as hardware infrastructure. The difference is that it employs a relatively determined and implementation-friendly CPE array for a group of applications instead of customized CPE array for each specific application. Since the CPE array is similar to the coarse grain reconfigurable array (CGRA) \cite{tessier2001reconfigurable} and still leaves kind for customization, we name it soft coarse grain reconfigurable array (SCGRA).


%The idea taking SCGRA as hardware infrastructure seems trivial, but it brings folded benefits to the HLS design method. On one hand, it allows us to pre-implement the SCGRA for a group or domain of applications. As long as the pre-implemented SCGRA can cover the target application, we can directly integrate the scheduling result into pre-implemented bitstream and have the application implemented without RTL compiling process. Consequently, the design productivity is promoted prominently. On the other hand, the SCGRA is well-defined and can be fully pipelined, so it can be implemented at almost extreme speed of the FPGA device. In this case, we can implement any applications supported by the SCGRA near full speed of the target FPGA device. Additionally, SCGRA based computation scheme also exhibits superiority on computation intensive applications. By combing both advantages in implementation frequency and computation efficiency, the proposed HLS method is able to provide the applications with high performance implementations.


The main contributions of this work can therefore be summarized as follows:
\begin{itemize}
\item A SCGRA based HLS methodology is proposed, which improves design productivity through bypassing the lengthy RTL compilation process.
\item A fully pipelined SCGRA is developed that executes at  almost full speed of the targeted FPGA device.
\item An efficient operation scheduling algorithm is implemented specially targeting the proposed fully pipelined SCGRA.
\end{itemize}

In \secref{sec:methodology}, the proposed methodology will be elaborated.  Our current SCGRA implementation will be presented in \secref{sec:scgra} and expreimental results shown in \secref{sec:results}.  Finally, we discuss limitation of current implementation in \secref{sec:discussion} and conclude in \secref{sec:conclusions}.

>>>>>>> .r2868
