@inproceedings{Tu2018RANA_1,
 author = {Tu, Fengbin and Wu, Weiwei and Yin, Shouyi and Liu, Leibo and Wei, Shaojun},
 title = {RANA: Towards Efficient Neural Acceleration with Refresh-optimized Embedded DRAM},
 booktitle = {Proceedings of the 45th Annual International Symposium on Computer Architecture},
 series = {ISCA '18},
 year = {2018},
 isbn = {978-1-5386-5984-7},
 location = {Los Angeles, California},
 pages = {340--352},
 numpages = {13},
 url = {https://doi.org/10.1109/ISCA.2018.00037},
 doi = {10.1109/ISCA.2018.00037},
 acmid = {3276573},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {embedded DRAM (eDRAM), neural network, refresh optimization, retention time},
} 

@INPROCEEDINGS{pipecnn_2, 
author={D. Wang and K. Xu and D. Jiang}, 
booktitle={2017 International Conference on Field Programmable Technology (ICFPT)}, 
title={PipeCNN: An OpenCL-based open-source FPGA accelerator for convolution neural networks}, 
year={2017}, 
volume={}, 
number={}, 
pages={279-282}, 
keywords={convolution;feedforward neural nets;field programmable gate arrays;pipeline processing;convolutional neural networks;CNNs;image classification;video analysis;speech recognition;high power dissipations;CNN accelerator;energy efficiency;fast verification;FPGA platforms;reconfigurable performance;PipeCNN project;FPGA accelerator;OpenCL-based open-source FPGA accelerator;OpenCL-based high-level synthesis tools;off-the-self design;hardware architectures;Kernel;Convolution;Field programmable gate arrays;Hardware;Bandwidth;Copper;Optimization}, 
doi={10.1109/FPT.2017.8280160}, 
ISSN={}, 
month={Dec},}

@INPROCEEDINGS{overclock_3, 
author={K. Shi and D. Boland and G. A. Constantinides}, 
booktitle={2013 IEEE 21st Annual International Symposium on Field-Programmable Custom Computing Machines}, 
title={Accuracy-Performance Tradeoffs on an FPGA through Overclocking}, 
year={2013}, 
volume={}, 
number={}, 
pages={29-36}, 
keywords={embedded systems;field programmable gate arrays;logic design;accuracy-performance tradeoffs;overclocking;embedded applications;stringent latency requirements;quantization error;timing violations;analytical models;FPGA-based accelerators;Xilinx Virtex-6;geometric mean reduction;error expectation;Field programmable gate arrays;Adders;Probabilistic logic;Clocks;Delays;Finite wordlength effects;FPGA;overclocking;probabilistic design}, 
doi={10.1109/FCCM.2013.10}, 
ISSN={}, 
month={April},}

@INPROCEEDINGS{DiCecco_4, 
author={R. DiCecco and G. Lacey and J. Vasiljevic and P. Chow and G. Taylor and S. Areibi}, 
booktitle={2016 International Conference on Field-Programmable Technology (FPT)}, 
title={Caffeinated FPGAs: FPGA framework For Convolutional Neural Networks}, 
year={2016}, 
volume={}, 
number={}, 
pages={265-268}, 
keywords={field programmable gate arrays;graphics processing units;learning (artificial intelligence);neural nets;performance evaluation;Caffeinated FPGA;convolutional neural networks;machine learning;GPU implementation performance;CNN framework Caffe;visual recognition;Xilinx SDAccel environment;FPGA-based Winograd convolution engine;AlexNet;GoogleNet;VGG A;Overfeat;GFLOPS;FPGA-based CNN;Field programmable gate arrays;Convolution;Parallel processing;Graphics processing units;Pipelines;Kernel;Computational modeling}, 
doi={10.1109/FPT.2016.7929549}, 
ISSN={}, 
month={Dec},}

@INPROCEEDINGS{fcnn_5, 
author={Wenlai Zhao and Haohuan Fu and W. Luk and Teng Yu and Shaojun Wang and Bo Feng and Yuchun Ma and Guangwen Yang}, 
booktitle={2016 IEEE 27th International Conference on Application-specific Systems, Architectures and Processors (ASAP)}, 
title={F-CNN: An FPGA-based framework for training Convolutional Neural Networks}, 
year={2016}, 
volume={}, 
number={}, 
pages={107-114}, 
keywords={field programmable gate arrays;floating point arithmetic;neural nets;32-bit floating-point arithmetic;hardware resources;bandwidth resources;streaming datapath;convolutional neural networks;FPGA-based framework;Training;Field programmable gate arrays;Convolution;Computational modeling;Bandwidth;Neural networks;Runtime}, 
doi={10.1109/ASAP.2016.7760779}, 
ISSN={2160-052X}, 
month={July},}

@ARTICLE{Caffeine_6, 
author={C. Zhang and G. Sun and Z. Fang and P. Zhou and P. Pan and J. Cong}, 
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
title={Caffeine: Towards Uniformed Representation and Acceleration for Deep Convolutional Neural Networks}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-1}, 
keywords={Field programmable gate arrays;Acceleration;Graphics processing units;Engines;Kernel;Bandwidth;Machine learning;convolutional neural network;deep learning;Caffe;CNN FPGA engine;hardware/software co-design.}, 
doi={10.1109/TCAD.2017.2785257}, 
ISSN={0278-0070}, 
month={},}

@inproceedings{lin2016_7,
 author = {Lin, Darryl D. and Talathi, Sachin S. and Annapureddy, V. Sreekanth},
 title = {Fixed Point Quantization of Deep Convolutional Networks},
 booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
 series = {ICML'16},
 year = {2016},
 location = {New York, NY, USA},
 pages = {2849--2858},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=3045390.3045690},
 acmid = {3045690},
 publisher = {JMLR.org},
}

@article{Matthieu2014_8,
  author    = {Matthieu Courbariaux and
               Yoshua Bengio and
               Jean{-}Pierre David},
  title     = {Low precision arithmetic for deep learning},
  journal   = {CoRR},
  volume    = {abs/1412.7024},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.7024},
  archivePrefix = {arXiv},
  eprint    = {1412.7024},
  timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/CourbariauxBD14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Zhang2015_9,
 author = {Zhang, Chen and Li, Peng and Sun, Guangyu and Guan, Yijin and Xiao, Bingjun and Cong, Jason},
 title = {Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks},
 booktitle = {Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
 series = {FPGA '15},
 year = {2015},
 isbn = {978-1-4503-3315-3},
 location = {Monterey, California, USA},
 pages = {161--170},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2684746.2689060},
 doi = {10.1145/2684746.2689060},
 acmid = {2689060},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {acceleration, convolutional neural network, fpga, roofline model},
}

@inproceedings{Qiu2016_10,
 author = {Qiu, Jiantao and Wang, Jie and Yao, Song and Guo, Kaiyuan and Li, Boxun and Zhou, Erjin and Yu, Jincheng and Tang, Tianqi and Xu, Ningyi and Song, Sen and Wang, Yu and Yang, Huazhong},
 title = {Going Deeper with Embedded FPGA Platform for Convolutional Neural Network},
 booktitle = {Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
 series = {FPGA '16},
 year = {2016},
 isbn = {978-1-4503-3856-1},
 location = {Monterey, California, USA},
 pages = {26--35},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2847263.2847265},
 doi = {10.1145/2847263.2847265},
 acmid = {2847265},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bandwidth utilization, convolutional neural network (cnn), dynamic-precision data quantization, embedded fpga},
}

@inproceedings{Jia:2014:CCA:2647868.2654889,
 author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
 title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
 booktitle = {Proceedings of the 22Nd ACM International Conference on Multimedia},
 series = {MM '14},
 year = {2014},
 isbn = {978-1-4503-3063-3},
 location = {Orlando, Florida, USA},
 pages = {675--678},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2647868.2654889},
 doi = {10.1145/2647868.2654889},
 acmid = {2654889},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computer vision, machine learning, neural networks, open source, parallel computation},
}

@inproceedings{deepburing_12,
 author = {Wang, Ying and Xu, Jie and Han, Yinhe and Li, Huawei and Li, Xiaowei},
 title = {DeepBurning: Automatic Generation of FPGA-based Learning Accelerators for the Neural Network Family},
 booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
 series = {DAC '16},
 year = {2016},
 isbn = {978-1-4503-4236-0},
 location = {Austin, Texas},
 pages = {110:1--110:6},
 articleno = {110},
 numpages = {6},
 doi = {10.1145/2897937.2898003},
 acmid = {2898003},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@INPROCEEDINGS{Farabet2010_13, 
author={C. Farabet and B. Martini and P. Akselrod and S. Talay and Y. LeCun and E. Culurciello}, 
booktitle={Proceedings of 2010 IEEE International Symposium on Circuits and Systems}, 
title={Hardware accelerated convolutional neural networks for synthetic vision systems}, 
year={2010}, 
volume={}, 
number={}, 
pages={257-260}, 
keywords={application specific integrated circuits;computer vision;field programmable gate arrays;image recognition;image segmentation;neural nets;scalable hardware architecture;convolutional neural network;state-of-the-art multilayered artificial vision system;vision engine;real time detection;real time recognition;real time segmentation;megapixel image;FPGA;ASIC;Neural network hardware;Acceleration;Neural networks;Machine vision;Artificial neural networks;Computer architecture;Large-scale systems;Multi-layer neural network;Engines;Real time systems}, 
doi={10.1109/ISCAS.2010.5537908}, 
ISSN={0271-4302}, 
month={May},}

@incollection{BinaryConnect_14,
title = {BinaryConnect: Training Deep Neural Networks with binary weights during propagations},
author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {3123--3131},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf}
}

@inproceedings{Paceline_15,
 author = {Greskamp, Brian and Torrellas, Josep},
 title = {Paceline: Improving Single-Thread Performance in Nanoscale CMPs Through Core Overclocking},
 booktitle = {Proceedings of the 16th International Conference on Parallel Architecture and Compilation Techniques},
 series = {PACT '07},
 year = {2007},
 isbn = {0-7695-2944-5},
 pages = {213--224},
 numpages = {12},
 url = {https://doi.org/10.1109/PACT.2007.52},
 doi = {10.1109/PACT.2007.52},
 acmid = {1299049},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

@article{DBLP:journals/corr/LinCMB15,
  author    = {Zhouhan Lin and
               Matthieu Courbariaux and
               Roland Memisevic and
               Yoshua Bengio},
  title     = {Neural Networks with Few Multiplications},
  journal   = {CoRR},
  volume    = {abs/1510.03009},
  year      = {2015},
  url       = {http://arxiv.org/abs/1510.03009},
  archivePrefix = {arXiv},
  eprint    = {1510.03009},
  timestamp = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LinCMB15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{Hwang2014_17, 
author={K. Hwang and W. Sung}, 
booktitle={2014 IEEE Workshop on Signal Processing Systems (SiPS)}, 
title={Fixed-point feedforward deep neural network design using weights +1, 0, and -1}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
keywords={backpropagation;character recognition;feedforward neural nets;fixed point arithmetic;signal processing;fixed-point feedforward deep neural network design;hardware complexity;backpropagation based retraining;ternary weights;3-bit signal;quantized weights;fixed-point signal;character recognition;phoneme recognition;Quantization (signal);Training;Backpropagation;Hardware;Error analysis;Feedforward neural networks}, 
doi={10.1109/SiPS.2014.6986082}, 
ISSN={2162-3562}, 
month={Oct},}

@inproceedings{Zeng2018_18,
 author = {Zeng, Hanqing and Chen, Ren and Zhang, Chi and Prasanna, Viktor},
 title = {A Framework for Generating High Throughput CNN Implementations on FPGAs},
 booktitle = {Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
 series = {FPGA '18},
 year = {2018},
 isbn = {978-1-4503-5614-5},
 location = {Monterey, CALIFORNIA, USA},
 pages = {117--126},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3174243.3174265},
 doi = {10.1145/3174243.3174265},
 acmid = {3174265},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {algorithmic optimization, convolutional neural networks, fast fourier trans- form, field programmable gate array, hardware mapping, software-hardware co-design},
}

@article{Yunchao_19,
  author    = {Yunchao Gong and
               Liu Liu and
               Ming Yang and
               Lubomir D. Bourdev},
  title     = {Compressing Deep Convolutional Networks using Vector Quantization},
  journal   = {CoRR},
  volume    = {abs/1412.6115},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.6115},
  archivePrefix = {arXiv},
  eprint    = {1412.6115},
  timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GongLYB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Mansour_20, 
author={W. Mansour and R. Velazco}, 
journal={IEEE Transactions on Nuclear Science}, 
title={An Automated SEU Fault-Injection Method and Tool for HDL-Based Designs}, 
year={2013}, 
volume={60}, 
number={4}, 
pages={2728-2733}, 
keywords={fault diagnosis;hardware description languages;integrated circuit design;integrated circuit testing;microcontrollers;radiation hardening (electronics);automated SEU fault-injection method;HDL-based design;soft-error sensitivity;integrated circuit;8051 microcontroller;SEU error-rate prediction;radiation ground testing;Circuit faults;Field programmable gate arrays;Hardware design languages;Integrated circuit modeling;Testing;Hardware;Program processors;Fault injection;hardware description language;single event upsets;SRAM-based FPGA}, 
doi={10.1109/TNS.2013.2267097}, 
ISSN={0018-9499}, 
month={Aug},}

@INPROCEEDINGS{Karim_21, 
author={S. Karim and J. Harkin and L. McDaid and B. Gardiner and J. Liu and D. M. Halliday and A. M. Tyrrell and J. Timmis and A. G. Millard and A. P. Johnson}, 
booktitle={2018 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
title={FPGA-based Fault-injection and Data Acquisition of Self-repairing Spiking Neural Network Hardware}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-5}, 
keywords={brain;data acquisition;data analysis;field programmable gate arrays;medical computing;neural nets;neurophysiology;FPGA-based fault-injection;data acquisition;human brain;astrocyte cells;distributed self-repair capability;fine-grained self-repair capability;synapse level;dedicated FPGA accelerators;astrocyte data;PC-based analysis;monitoring platform;FMP;SANN FPGA accelerator;NIOS II based system;data monitoring;accurate accelerated simulations;fault injection scenarios;adaptive-repair feature;astrocyte-neuron networks model;off-chip transmission;self-repairing spiking neural network hardware;Field programmable gate arrays;Matlab;Synapses;Neurons;Monitoring;SDRAM;FPGA acceleration;Data Acquisition;Astrocytes;Spiking neural network;Self repair;Fault injection}, 
doi={10.1109/ISCAS.2018.8351512}, 
ISSN={2379-447X}, 
month={May},}

@INPROCEEDINGS{Nidhin_22, 
author={T. S. Nidhin and A. Bhattacharyya and R. P. Behera and T. Jayanthi and K. Velusamy}, 
booktitle={2017 4th International Conference on Electronics and Communication Systems (ICECS)}, 
title={Verification of fault tolerant techniques in finite state machines using simulation based fault injection targeted at FPGAs for SEU mitigation}, 
year={2017}, 
volume={}, 
number={}, 
pages={153-157}, 
keywords={error detection;fault tolerance;field programmable gate arrays;finite state machines;radiation hardening (electronics);finite state machines;simulation based fault injection;Field Programmable Gate Arrays;FPGA based designs;Nuclear Power Plants special care;fault injection technique;PREP3 state machine;fault tolerant techniques;SEU mitigation;safe FSM synthesis;Triple Modular Redundancy;TMR;Field programmable gate arrays;Circuit faults;Fault tolerance;Fault tolerant systems;Single event upsets;Tunneling magnetoresistance;FPGA;Single Event Upset (SEU);Fault tolerance;Finite State Machine;TMR;Fault Injection}, 
doi={10.1109/ECS.2017.8067859}, 
ISSN={}, 
month={Feb},}

@inproceedings{Subasi_23,
 author = {Subasi, Omer and Chang, Chun-Kai and Erez, Mattan and Krishnamoorthy, Sriram},
 title = {Characterizing the Impact of Soft Errors Affecting Floating-point ALUs Using RTL-Ievel Fault Injection},
 booktitle = {Proceedings of the 47th International Conference on Parallel Processing},
 series = {ICPP 2018},
 year = {2018},
 isbn = {978-1-4503-6510-9},
 location = {Eugene, OR, USA},
 pages = {59:1--59:10},
 articleno = {59},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3225058.3225089},
 doi = {10.1145/3225058.3225089},
 acmid = {3225089},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fault injection experiments, RTL simulation},
}

@article{ROSCH_24,
title = "A Light-Weight Fault Injection Approach to Test Automated Production System PLC Software in Industrial Practice",
journal = "Control Engineering Practice",
volume = "58",
pages = "12 - 23",
year = "2017",
issn = "0967-0661",
doi = "https://doi.org/10.1016/j.conengprac.2016.09.012",
url = "http://www.sciencedirect.com/science/article/pii/S0967066116302143",
author = "Susanne Rösch and Birgit Vogel-Heuser",
keywords = "Automated production system, Software-implemented fault injection, Automated software testing, Programmable logic controller, Error handling",
abstract = "A light-weight software-implemented fault injection (SWIFI) testing approach is introduced, focusing on technical process faults and system faults. The reaction of automated production systems (aPSs) and their programmable logic controller (PLC) software to these faults is tested. In order to tailor the testing approach to the aPS domain in industrial practice, our test generation is based on a classification of possible deviations, i.e. a classification of possible technical process and system faults as the PLC perceives them. As a result, both specification and test execution become more efficient for practitioners. Furthermore, the test specification is tailored for execution on IEC 61131-3 programming environments. In this, the execution of test cases both against simulation or the real aPS, is enabled."
}

@inproceedings{Cnvlutin_25,
 author = {Albericio, Jorge and Judd, Patrick and Hetherington, Tayler and Aamodt, Tor and Jerger, Natalie Enright and Moshovos, Andreas},
 title = {Cnvlutin: Ineffectual-neuron-free Deep Neural Network Computing},
 booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},
 series = {ISCA '16},
 year = {2016},
 isbn = {978-1-4673-8947-1},
 location = {Seoul, Republic of Korea},
 pages = {1--13},
 numpages = {13},
 url = {https://doi.org/10.1109/ISCA.2016.11},
 doi = {10.1109/ISCA.2016.11},
 acmid = {3001138},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
}

@INPROCEEDINGS{7493228, 
author={M. Bromberger and P. Bastian and J. Bergeest and C. Conrad and V. Heuveline and K. Rohr and W. Karl}, 
booktitle={2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)}, 
title={FPGA-accelerated Richardson-Lucy deconvolution for 3D image data}, 
year={2016}, 
volume={}, 
number={}, 
pages={132-135}, 
keywords={deconvolution;field programmable gate arrays;medical image processing;optical microscopy;FPGA-accelerated Richardson-Lucy deconvolution;CPU architectures;computation time;3D image data processing;single-plane illumination microscopy;Three-dimensional displays;Convolution;Field programmable gate arrays;Deconvolution;Microscopy;Acceleration;Random access memory;3D deconvolution;field-programmable gate array (FPGA);heterogeneous system;preprocessing of 3D image data}, 
doi={10.1109/ISBI.2016.7493228}, 
ISSN={1945-8452}, 
month={April},}

@inproceedings{Aydonat_27,
 author = {Aydonat, Utku and O'Connell, Shane and Capalija, Davor and Ling, Andrew C. and Chiu, Gordon R.},
 title = {An OpenCL\texttrademark Deep Learning Accelerator on Arria 10},
 booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
 series = {FPGA '17},
 year = {2017},
 isbn = {978-1-4503-4354-1},
 location = {Monterey, California, USA},
 pages = {55--64},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3020078.3021738},
 doi = {10.1145/3020078.3021738},
 acmid = {3021738},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {convolutional neural networks, deep neural networks},
}

@inproceedings{Subasi:2018:CIS:3225058.3225089,
 author = {Subasi, Omer and Chang, Chun-Kai and Erez, Mattan and Krishnamoorthy, Sriram},
 title = {Characterizing the Impact of Soft Errors Affecting Floating-point ALUs Using RTL-Ievel Fault Injection},
 booktitle = {Proceedings of the 47th International Conference on Parallel Processing},
 series = {ICPP 2018},
 year = {2018},
 isbn = {978-1-4503-6510-9},
 location = {Eugene, OR, USA},
 pages = {59:1--59:10},
 articleno = {59},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3225058.3225089},
 doi = {10.1145/3225058.3225089},
 acmid = {3225089},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fault injection experiments, RTL simulation},
}

@inproceedings{Wei_29,
 author = {Wei, Xuechao and Yu, Cody Hao and Zhang, Peng and Chen, Youxiang and Wang, Yuxin and Hu, Han and Liang, Yun and Cong, Jason},
 title = {Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs},
 booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},
 series = {DAC '17},
 year = {2017},
 isbn = {978-1-4503-4927-7},
 location = {Austin, TX, USA},
 pages = {29:1--29:6},
 articleno = {29},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3061639.3062207},
 doi = {10.1145/3061639.3062207},
 acmid = {3062207},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Subasi_30,
 author = {Subasi, Omer and Chang, Chun-Kai and Erez, Mattan and Krishnamoorthy, Sriram},
 title = {Characterizing the Impact of Soft Errors Affecting Floating-point ALUs Using RTL-Ievel Fault Injection},
 booktitle = {Proceedings of the 47th International Conference on Parallel Processing},
 series = {ICPP 2018},
 year = {2018},
 isbn = {978-1-4503-6510-9},
 location = {Eugene, OR, USA},
 pages = {59:1--59:10},
 articleno = {59},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3225058.3225089},
 doi = {10.1145/3225058.3225089},
 acmid = {3225089},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fault injection experiments, RTL simulation},
}

@inproceedings{Approximate_Multiplier_31,
 author = {Hashemi, Soheil and Bahar, R. Iris and Reda, Sherief},
 title = {DRUM: A Dynamic Range Unbiased Multiplier for Approximate Applications},
 booktitle = {Proceedings of the IEEE/ACM International Conference on Computer-Aided Design},
 series = {ICCAD '15},
 year = {2015},
 isbn = {978-1-4673-8389-9},
 location = {Austin, TX, USA},
 pages = {418--425},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2840819.2840878},
 acmid = {2840878},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
}

@ARTICLE{Approximate_32, 
author={X. He and S. Jiang and W. Lu and G. Yan and Y. Han and X. Li}, 
journal={IEEE Transactions on Multi-Scale Computing Systems}, 
title={Exploiting the Potential of Computation Reuse Through Approximate Computing}, 
year={2017}, 
volume={3}, 
number={3}, 
pages={152-165}, 
keywords={computer architecture;parallel processing;regression analysis;ACR;approximate computation reuse;approximate computing;input significance-aware similarity quantification;regression based branch prediction technique;parallel computing engine implementation;Approximate computing;Computational modeling;Impedance matching;History;Engines;Benchmark testing;Associative memory;Approximate computing;computation reuse;similarity quantification;content addressable memory;regression techniques}, 
doi={10.1109/TMSCS.2016.2617343}, 
ISSN={2332-7766}, 
month={July},} 

@INPROCEEDINGS{approximate_33, 
author={B. Moons and B. De Brabandere and L. Van Gool and M. Verhelst}, 
booktitle={2016 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
title={Energy-efficient ConvNets through approximate computing}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-8}, 
keywords={approximation theory;embedded systems;energy consumption;image classification;neural nets;object detection;energy-efficient ConvNets;approximate computing;convolutional neural networks;classification algorithms;detection algorithms;near-human performance;visual detection;wearable platforms;embedded systems;energy consumption;fixed point number format;Quantization (signal);Energy consumption;Computer architecture;Neural networks;Hardware;Approximation algorithms}, 
doi={10.1109/WACV.2016.7477614}, 
ISSN={}, 
month={March},}

@INPROCEEDINGS{overclock_retain_34, 
author={J. Deng and Y. Rang and Z. Du and Y. Wang and H. Li and O. Temam and P. Ienne and D. Novo and X. Li and Y. Chen and C. Wu}, 
booktitle={2015 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={Retraining-based timing error mitigation for hardware neural networks}, 
year={2015}, 
volume={}, 
number={}, 
pages={593-596}, 
keywords={fault tolerant computing;learning (artificial intelligence);neural nets;retraining-based timing error mitigation;hardware neural networks;error resiliency;NN accelerators;Biological neural networks;Delays;Logic gates;Accuracy;Neurons;neural networks;error tolerance;machine learning;timing errors;overclocking}, 
doi={}, 
ISSN={1530-1591}, 
month={March},}

@INPROCEEDINGS{overclock_35, 
author={K. Shi and D. Boland and E. Stott and S. Bayliss and G. A. Constantinides}, 
booktitle={2014 51st ACM/EDAC/IEEE Design Automation Conference (DAC)}, 
title={Datapath synthesis for overclocking: Online arithmetic for latency-accuracy trade-offs}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
keywords={clocks;field programmable gate arrays;timing circuits;datapath synthesis;overclocking;online arithmetic;latency-accuracy trade-offs;digital circuits;timing violations;computer arithmetic;digit serial operation;unrolled digit parallel online operators;key arithmetic primitives;binary arithmetic;timing errors;FPGA;image processing;Delays;Adders;Field programmable gate arrays;Clocks;Standards;Probabilistic logic;Online Arithmetic;Overclocking;Imprecise Design}, 
doi={10.1145/2593069.2593118}, 
ISSN={0738-100X}, 
month={June},}

@techreport{overclock_Algorithm_36,
  TITLE = {{Algorithm Level Timing Speculation for Convolutional Neural Network Accelerators}},
  AUTHOR = {Marty, Thibaut and Yuki, Tomofumi and Derrien, Steven},
  URL = {https://hal.inria.fr/hal-01811231},
  TYPE = {Technical Report},
  NUMBER = {RT-0500},
  PAGES = {1-17},
  INSTITUTION = {{Univ Rennes, Inria, CNRS, IRISA, France}},
  YEAR = {2018},
  MONTH = Jun,
  KEYWORDS = {Algorithm Based Fault Tolerance ;  Convolutional Neural Network ;  High-level synthesis ;  Timing speculation},
  PDF = {https://hal.inria.fr/hal-01811231/file/RT-0500.pdf},
  HAL_ID = {hal-01811231},
  HAL_VERSION = {v1},
}

@Misc{model-accuracy,
	howpublished = {\url{https://pjreddie.com/darknet/imagenet/#alexnet}},
	note = {Accessed Jan 4, 2019},
	title = {ImageNet Classification},
	author = {Joseph Chet Redmon}
}

@article{distillation_38,
  author    = {Asit K. Mishra and
               Debbie Marr},
  title     = {Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision
               Network Accuracy},
  journal   = {CoRR},
  volume    = {abs/1711.05852},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.05852},
  archivePrefix = {arXiv},
  eprint    = {1711.05852},
  timestamp = {Mon, 13 Aug 2018 16:46:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1711-05852},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{distillation_39,
title	= {Distilling the Knowledge in a Neural Network},
author	= {Geoffrey Hinton and Oriol Vinyals and Jeffrey Dean},
year	= {2015},
URL	= {http://arxiv.org/abs/1503.02531},
booktitle	= {NIPS Deep Learning and Representation Learning Workshop}
}

@inproceedings{Miao_40,
 author = {Miao, Jin and He, Ku and Gerstlauer, Andreas and Orshansky, Michael},
 title = {Modeling and Synthesis of Quality-energy Optimal Approximate Adders},
 booktitle = {Proceedings of the International Conference on Computer-Aided Design},
 series = {ICCAD '12},
 year = {2012},
 isbn = {978-1-4503-1573-9},
 location = {San Jose, California},
 pages = {728--735},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2429384.2429542},
 doi = {10.1145/2429384.2429542},
 acmid = {2429542},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@INPROCEEDINGS{han_41, 
author={Y. Han and Y. Wang and H. Li and X. Li}, 
booktitle={2013 IEEE International Symposium on Circuits and Systems (ISCAS2013)}, 
title={Enabling Near-Threshold Voltage(NTV) operation in Multi-VDD cache for power reduction}, 
year={2013}, 
volume={}, 
number={}, 
pages={337-340}, 
keywords={cache storage;integrated circuit reliability;SRAM chips;near-threshold voltage operation SRAM;multiVDD cache;power reduction;power constraint;cache capacity;multimany core processors;DVFS;last level cache;processor chip;power management strategy;NTV SRAM;multivoltage domain cache;data corruption;redundancy-based data salvaging technique;fault recovery;reliability guarantee;vulnerable-invulnerable data sets;high-low voltage domains;redundancy masking effects;energy efficiency;Random access memory;Program processors;Redundancy;Low voltage;Error correction codes;Power demand}, 
doi={10.1109/ISCAS.2013.6571849}, 
ISSN={0271-4302}, 
month={May},}

@inproceedings{Reagen_42,
 author = {Reagen, Brandon and Whatmough, Paul and Adolf, Robert and Rama, Saketh and Lee, Hyunkwang and Lee, Sae Kyu and Hern\'{a}ndez-Lobato, Jos{\'e} Miguel and Wei, Gu-Yeon and Brooks, David},
 title = {Minerva: Enabling Low-power, Highly-accurate Deep Neural Network Accelerators},
 booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},
 series = {ISCA '16},
 year = {2016},
 isbn = {978-1-4673-8947-1},
 location = {Seoul, Republic of Korea},
 pages = {267--278},
 numpages = {12},
 url = {https://doi.org/10.1109/ISCA.2016.32},
 doi = {10.1109/ISCA.2016.32},
 acmid = {3001165},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 

@inproceedings{AxNN_43,
 author = {Venkataramani, Swagath and Ranjan, Ashish and Roy, Kaushik and Raghunathan, Anand},
 title = {AxNN: Energy-efficient Neuromorphic Systems Using Approximate Computing},
 booktitle = {Proceedings of the 2014 International Symposium on Low Power Electronics and Design},
 series = {ISLPED '14},
 year = {2014},
 isbn = {978-1-4503-2975-0},
 location = {La Jolla, California, USA},
 pages = {27--32},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2627369.2627613},
 doi = {10.1145/2627369.2627613},
 acmid = {2627613},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {approximate computing, energy efficiency, large-scale neural networks, neuromorphic systems},
}

@inproceedings{approxANN_44,
 author = {Zhang, Qian and Wang, Ting and Tian, Ye and Yuan, Feng and Xu, Qiang},
 title = {ApproxANN: An Approximate Computing Framework for Artificial Neural Network},
 booktitle = {Proceedings of the 2015 Design, Automation \&\#38; Test in Europe Conference \&\#38; Exhibition},
 series = {DATE '15},
 year = {2015},
 isbn = {978-3-9815370-4-8},
 location = {Grenoble, France},
 pages = {701--706},
 numpages = {6},
 url = {http://dl.acm.org/citation.cfm?id=2755753.2755913},
 acmid = {2755913},
 publisher = {EDA Consortium},
 address = {San Jose, CA, USA},
}  

@INPROCEEDINGS{appro_45, 
author={C. Liu and J. Han and F. Lombardi}, 
booktitle={2014 Design, Automation Test in Europe Conference Exhibition (DATE)}, 
title={A low-power, high-performance approximate multiplier with configurable partial error recovery}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-4}, 
keywords={adders;CMOS integrated circuits;digital signal processing chips;multiplying circuits;system recovery;low-power approximate multiplier;high-performance approximate multiplier;configurable partial error recovery;approximate circuits;error-tolerant applications;digital signal processing;DSP;approximate adder;partial product accumulation;configurable error recovery;most significant bits;MSB;error reduction;mean error distance;CMOS process;size 28 nm;word length 16 bit;Adders;Delays;Approximation methods;Accuracy;Vectors;Vegetation;Logic gates}, 
doi={10.7873/DATE.2014.108}, 
ISSN={1530-1591}, 
month={March},}

@ARTICLE{appro_46, 
author={A. Pullini and F. Conti and D. Rossi and I. Loi and M. Gautschi and L. Benini}, 
journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
title={A Heterogeneous Multicore System on Chip for Energy Efficient Brain Inspired Computing}, 
year={2018}, 
volume={65}, 
number={8}, 
pages={1094-1098}, 
keywords={convolution;coprocessors;feedforward neural nets;Internet of Things;mixed analogue-digital integrated circuits;multiprocessing systems;parallel processing;pattern clustering;system-on-chip;stack processing;IoT node;edge node Internet-of-things applications;deeply embedded devices;near-sensors processing;speech recognition;computer vision;convolutional neural networks;energy efficient brain inspired computing;heterogeneous multicore system;peak energy efficiency;CNN accelerator;near-threshold parallel processor cluster;65-nm system-on-chip;nonconventional sensory algorithms;arbitrary CNN topologies;Computer architecture;Convolution;Topology;Nickel;Neural networks;System-on-chip;Hardware;Convolutional neural networks (CNNs);heterogeneous computing;multiprocessor system on a chip (SoC);near threshold computing}, 
doi={10.1109/TCSII.2017.2652982}, 
ISSN={1549-7747}, 
month={Aug},}

@inproceedings{Razor,
 author = {Ernst, Dan and Kim, Nam Sung and Das, Shidhartha and Pant, Sanjay and Rao, Rajeev and Pham, Toan and Ziesler, Conrad and Blaauw, David and Austin, Todd and Flautner, Krisztian and Mudge, Trevor},
 title = {Razor: A Low-Power Pipeline Based on Circuit-Level Timing Speculation},
 booktitle = {Proceedings of the 36th Annual IEEE/ACM International Symposium on Microarchitecture},
 series = {MICRO 36},
 year = {2003},
 isbn = {0-7695-2043-X},
 pages = {7--},
 url = {http://dl.acm.org/citation.cfm?id=956417.956571},
 acmid = {956571},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

@INPROCEEDINGS{B2006,
author={B. {Zhai} and L. {Nazhandali} and J. {Olson} and A. {Reeves} and M. {Minuth} and R. {Helfand} and S. {Pant} and D. {Blaauw} and T. {Austin}},
booktitle={2006 Symposium on VLSI Circuits, 2006. Digest of Technical Papers.},
title={A 2.60pJ/Inst Subthreshold Sensor Processor for Optimal Energy Efficiency},
year={2006},
volume={},
number={},
pages={154-155},
keywords={CMOS digital integrated circuits;instruction sets;integrated circuit design;microprocessor chips;sensors;subthreshold sensor processor;process variation;subthreshold operation;library cell selection;SRAM design;optimal energy efficiency;adaptive control;0.2 to 1.2 V;833 kHz;Energy efficiency;Delay;Libraries;Random access memory;Frequency;Circuits;Dynamic voltage scaling;Resource description framework;Energy consumption;Pipelines},
doi={10.1109/VLSIC.2006.1705356},
ISSN={2158-5601},
month={June},}

@ARTICLE{BH2005,
author={B. H. {Calhoun} and A. {Wang} and A. {Chandrakasan}},
journal={IEEE Journal of Solid-State Circuits},
title={Modeling and sizing for minimum energy operation in subthreshold circuits},
year={2005},
volume={40},
number={9},
pages={1778-1786},
keywords={circuit optimisation;integrated circuit modelling;integrated circuit design;low-power electronics;digital integrated circuits;minimum energy operation;subthreshold circuits;energy minimization;energy-saving approach;circuit optimisation;integrated circuit modelling;integrated circuit design;low-power electronics;Semiconductor device measurement;Minimization;Frequency;Energy consumption;Threshold voltage;Instruments;Equations;Circuit testing;Energy measurement;Measurement standards;Energy model;low voltage operation;minimum energy point;subthreshold logic},
doi={10.1109/JSSC.2005.852162},
ISSN={0018-9200},
month={Sep.},}

@ARTICLE{RG2010NT,
author={R. G. {Dreslinski} and M. {Wieckowski} and D. {Blaauw} and D. {Sylvester} and T. {Mudge}},
journal={Proceedings of the IEEE},
title={Near-Threshold Computing: Reclaiming Moore's Law Through Energy Efficient Integrated Circuits},
year={2010},
volume={98},
number={2},
pages={253-266},
keywords={energy conservation;energy consumption;integrated circuit design;power integrated circuits;near-threshold computing;Moores law;energy efficient integrated circuits;energy consumption;power-constrained computing;Moore's Law;Energy efficiency;CMOS technology;Threshold voltage;Computer architecture;Fabrication;Clocks;Design optimization;Energy consumption;High performance computing;CMOS integrated circuits;computer architecture;energy conservation;parallel processing;VLSI},
doi={10.1109/JPROC.2009.2034764},
ISSN={0018-9219},
month={Feb},}

@INPROCEEDINGS{Reagen2016,
author={B. {Reagen} and P. {Whatmough} and R. {Adolf} and S. {Rama} and H. {Lee} and S. K. {Lee} and J. M. {Hernández-Lobato} and G. {Wei} and D. {Brooks}},
booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)},
title={Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators},
year={2016},
volume={},
number={},
pages={267-278},
keywords={neural nets;Minerva;deep neural network accelerators;deep neural networks;classification tasks;specialized hardware;magnitude improvement;general-purpose hardware;automated codesign;DNN hardware accelerators;fixed-point accelerator baseline;heterogeneous datatype optimization;inline predication;small activity values;active hardware fault detection;domain-aware error mitigation;SRAM voltages;DNN model accuracy;ultra-low power DNN accelerators;power-constrained IoT;mobile devices;Optimization;Random access memory;Hardware;Integrated circuit modeling;Circuit faults;Space exploration;Libraries},
doi={10.1109/ISCA.2016.32},
ISSN={1063-6897},
month={June},}

@article{Han2016DeepCC,
  title={Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding},
  author={Song Han and Huizi Mao and William J. Dally},
  journal={CoRR},
  year={2016},
  volume={abs/1510.00149}
}

@ARTICLE{M2017NT, 
author={M. {Gautschi} and P. D. {Schiavone} and A. {Traber} and I. {Loi} and A. {Pullini} and D. {Rossi} and E. {Flamand} and F. K. {Gürkaynak} and L. {Benini}}, 
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
title={Near-Threshold RISC-V Core With DSP Extensions for Scalable IoT Endpoint Devices}, 
year={2017}, 
volume={25}, 
number={10}, 
pages={2700-2713}, 
keywords={buffer circuits;CMOS integrated circuits;digital signal processing chips;Internet of Things;reduced instruction set computing;silicon-on-insulator;endpoint devices;Internet-of-Things;near-threshold operation;open-source RISC-V processor core;tightly coupled multicore clusters;instruction extensions;microarchitectural optimizations;computational density;shared-memory hierarchy;data-intensive sensor processing workloads;smart L0 buffer;cache access contentions;compressed instructions;single instruction multiple data extensions;bulk CMOS technology;FD-SOI process;DSP extensions;voltage 0.6 V to 1.2 V;size 65 nm;size 28 nm;frequency 40 MHz;power 1 mW;Instruction set architecture (ISA) extensions;Internet-of-Things;multicore;RISC-V;ultralow power (ULP)}, 
doi={10.1109/TVLSI.2017.2654506}, 
ISSN={1063-8210}, 
month={Oct},}

@inproceedings{Pu2010NT,
 author = {Pu, Yu and Zhang, Xin and Huang, Jim and Muramatsu, Atsushi and Nomura, Masahiro and Hirairi, Koji and Takata, Hidehiro and Sakurabayashi, Taro and Miyano, Shinji and Takamiya, Makoto and Sakurai, Takayasu},
 title = {Misleading Energy and Performance Claims in Sub/Near Threshold Digital Systems},
 booktitle = {Proceedings of the International Conference on Computer-Aided Design},
 series = {ICCAD '10},
 year = {2010},
 isbn = {978-1-4244-8192-7},
 location = {San Jose, California},
 pages = {625--631},
 numpages = {7},
 acmid = {2133562},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
}

@inproceedings{Schrijen2012SRAM,
 author = {Schrijen, Geert-Jan and van der Leest, Vincent},
 title = {Comparative Analysis of SRAM Memories Used As PUF Primitives},
 booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
 series = {DATE '12},
 year = {2012},
 isbn = {978-3-9810801-8-6},
 location = {Dresden, Germany},
 pages = {1319--1324},
 numpages = {6},
 url = {http://dl.acm.org/citation.cfm?id=2492708.2493033},
 acmid = {2493033},
 publisher = {EDA Consortium},
 address = {San Jose, CA, USA},
} 

@ARTICLE{G2010SRAM, 
author={G. {Chen} and D. {Sylvester} and D. {Blaauw} and T. {Mudge}}, 
journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
title={Yield-Driven Near-Threshold SRAM Design}, 
year={2010}, 
volume={18}, 
number={11}, 
pages={1590-1598}, 
keywords={circuit stability;importance sampling;integrated circuit design;low-power electronics;SRAM chips;VLSI;yield-driven near-threshold SRAM design;voltage scaling;static RAM;energy consumption reduction;6T bit cell;8T bit cell;doped bit cells;sized bit cells;SRAM robustness;importance sampling;leakage;minimum total energy operation;supply voltage;dynamic energy reduction;activity factor;VLSI;assist circuits;Random access memory;Dynamic voltage scaling;Delay;Energy consumption;Circuits;Resource description framework;Monte Carlo methods;Read-write memory;Noise robustness;Noise reduction;Low power;near threshold;robustness;static RAM (SRAM);threshold voltage tuning}, 
doi={10.1109/TVLSI.2009.2025766}, 
ISSN={1063-8210}, 
month={Nov},}

@INPROCEEDINGS{SA2008SRAM, 
author={S. A. {Tawfik} and V. {Kursun}}, 
booktitle={2008 IEEE International Symposium on Circuits and Systems}, 
title={Low power and robust 7T dual-Vt SRAM circuit}, 
year={2008}, 
volume={}, 
number={}, 
pages={1452-1455}, 
keywords={circuit stability;low-power electronics;SRAM chips;transistors;robust 7T dual-Vt SRAM circuit;seven transistors;threshold voltage;data stability;cross-coupled inverters;static noise margin;leakage power consumptions;write power consumptions;standby mode power consumption;Robustness;Random access memory;Energy consumption;Circuit stability;Inverters;CMOS technology;Threshold voltage;Delay;Degradation;Circuit noise}, 
doi={10.1109/ISCAS.2008.4541702}, 
ISSN={0271-4302}, 
month={May},}

@ARTICLE{courbariaux2014,
    author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
     month = dec,
     title = {Training deep neural networks with low precision multiplications},
   journal = {arXiv e-prints},
    volume = {abs/1412.7024},
      year = {2014},
       url = {http://arxiv.org/abs/1412.7024},
  abstract = {We simulate the training of a set of state of the art neural networks, the Maxout networks (Goodfellow et al., 2013a), on three benchmark datasets: the MNIST, CIFAR10 and SVHN, with three distinct arithmetics: floating point, fixed point and dynamic fixed point. For each of those datasets and for each of those arithmetics, we assess the impact of the precision of the computations on the final error of the training. We find that very low precision computation is sufficient not just for running trained networks but also for training them. For example, almost state-of-the-art results were obtained on most datasets with 10 bits for computing activations and gradients, and 12 bits for storing updated parameters.}
}

@INPROCEEDINGS{B2018ARES, 
author={B. {Reagen} and U. {Gupta} and L. {Pentecost} and P. {Whatmough} and S. K. {Lee} and N. {Mulholland} and D. {Brooks} and G. {Wei}}, 
booktitle={2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)}, 
title={Ares: A framework for quantifying the resilience of deep neural networks}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-6}, 
keywords={CAD;neural nets;software fault tolerance;Ares;deep neural networks;compute cycles;architecture communities;DNN hardware;DNN resilience;inherent algorithmic resilience;fault rate;DNN-specific fault injection framework;CAD;DNN fault tolerance;Circuit faults;Hardware;Fault tolerance;Fault tolerant systems;Resilience;Random access memory;Neural networks}, 
doi={10.1109/DAC.2018.8465834}, 
ISSN={}, 
month={June},}
