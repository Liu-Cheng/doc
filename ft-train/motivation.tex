\section{Motivation} \label{sec:motivation}
Nowadays, the main stream training frameworks typically adopt the offline training
on GPPs to obtain the neural network models and then apply the quantized models to the 
target CNN accelerators. When the computing on the underlying CNN accelerators differs
from that calculated with GPPs due to the approximate arithmetic logic, overclocking or 
soft errors, the offline trained neural network models executed on the accelerator 
may deviate from the expected computing result. To evaluate the influence, 
we take Alexnet as an example to evaluate the prediction 
accuracy loss when the offline trained model is deployed on the CNN 
accelerators with approximate multiplier, overclocking, and soft errors respectively. 

In the experiment, we use PipeCNN\cite{pipecnn_2}, an open sourced high-level CNN accelerator, 
as the baseline design. We have it implemented 
on KCU1500 FPGA board and run at 210 MHz for AlexNet. 

On a subset of ImageNet, we train AlexNet offline 
and then apply it to the accelerator. The resulting top-5 accuracy is 78.95\%. Then the clock 
frequency is boosted to 250Mhz and 260MHz respectively, we apply the original model on 
the overclocked accelerator. The performance gets improved proportionally, but the 
accuracy drops 0.5\% and 4.3\% respectively.

  Soft error has become an un-ignorable problem with the shrinking semiconductor 
feature size and we further analyze its influence on the CNN accelerator. 
Currently, we use a uniform distribution model to inject the SEU errors to the 
multiplication-accumulation operators (MAC) of the accelerator. It causes one-bit 
flip on random bits of the MAC results. When the error injection rate is set to 
be 0.0001\% per MAC, applying the off-line trained model to the CNN accelerator 
leads to around 0.7\% accuracy loss of the top 5 prediction. When error injection 
rate is set to be 0.001\% per MAC, the prediction accuracy drops around 3\%.

  To gain insight on the precision drop, we also check the output of the AlexNet’s last 
layer. We compare the data and find that the data deviates from expected result slightly 
due to the ‘unstable’ accelerator. But the accuracy loss of the model deployed on 
the ‘unstable’ CNN accelerator cannot be ignored according to the experiments. 
And it is highly demanded to explore the training 
system and take the accelerators’ behavior into consideration during training for higher prediction accuracy.

\begin{figure}
	\center{\includegraphics[width=0.75\linewidth]{Loss}}
    \caption{Prediction accuracy loss of offline trained Alexnet on CNN accelerators with approximate multiplier, overclocking and soft errors respectively.}
\label{fig:loss}
\vspace{-1em}
\end{figure}


