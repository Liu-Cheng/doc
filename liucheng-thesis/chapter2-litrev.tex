\chapter{Literature Review} \label{chapter:litrev}
The use of FPGA as compute accelerators has been demonstrated to be successful in many domains of applications \cite{iouliia2004reconfigurable, souradip2010hardware, asano2009performance, che2008accelerating, thomas2009comparison}. However, the FPGA accelerator development is mostly carried out at relatively low abstraction level and limited to highly trained hardware specialists. As a result, the use of FPGA as accelerators in mainstream computing system is rather limited especially compared to that of Xeon Phi accelerators and GPU accelerators \cite{top500} which have much shorter history but get wide adoption in many computing systems. One of the major reasons that hinder the wide adoption of FPGAs as computing accelerators is the extremely low design productivity caused by both the lengthy FPGA compilation and the low-level design entry barrier. More and more researchers from both industry and academia believe that improving the FPGA design productivity by offering programmable FPGAs to software designers is the key to extend the reach of FPGAs in future \cite{cong2011high, raje2015fpl, fsp2015, fsp2014, olaf2013}. 

Over the past decades, significant progress has been made to enhance the design productivity of the FPGA development and many different approaches have been explored. This section will review these approaches and it is organized as follows. The approaches developed for improving the productivity of the FPGA development will be classified and briefly introduced in next section. Then the overlay architectures that are most relevant to this work will be reviewed in detail. Finally, related work of overlay customization specifically to target applications are presented.

\section{Approaches to Improve FPGA Design Productivity}
In order to improve the FPGA design productivity of the designers, many approaches from various angles focusing on the different processes of the FPGA development including raising the FPGA abstraction level of the design entry, reducing FPGA implementation time, automating the design space exploration, providing hardware/software support during run-time and compile-time and offering FPGA debugging facilities have been proposed over the years. They will be introduced in the rest part of this section. 

\subsection{Raising the Abstraction Level}
Recent advances in HLS tools have significantly raised the abstraction level and lowered the design entry of the FPGA development \cite{cong2011high}. Instead of using hardware description languages (HDLs) for the hardware design at register transfer level (RTL) or behavioral level, high-level languages such as C/C++, OpenCL, Python and Matlab \cite{canis2011legup, cardoso2011compilation, handel-c, ROCCC, matlab, myhdl, OpenCL, VivadoHLS}, which the software designers are likely to be familiar with or at least comfortable to pick up, are used for the FPGA development. When the applications or algorithms are implemented with the high-level languages, the resulting high-level language programs are then compiled to logic gates which are usually expressed in HDLs. Afterwards, the logic gates can be further mapped to the underlying FPGA fabrics automatically which is the same with the conventional HDL based FPGA development. Ideally, the HLS tools make the FPGA low-level design details transparent to the application developers and thus lower the design entry of FPGA development. In addition, HLS tools allow complex functionality to be expressed more easily in most cases compared to the conventional hardware design using HDLs and also help the users to develop complex hardware system more efficiently. 

Another way to raise the abstraction level is to build an advanced computing architecture overlay such as soft processor overlays, CGRA overlays and GPU overlays on top of the fine-grained FPGA fabrics \cite{cheah2012iDEA, laforest2012OCTAVO, yiannacouras2007exploration, ferreira2011fpga, kissler2006dynamically, shukla2006quku, lin2012energy, capalijia2013pipelined, jeffrey2011potential}. Instead of programming on the fine-grained FPGA fabrics, the designers may program on these overlays. These overlays with advanced computing architectures are typically easier for software designers to program with high-level languages. Therefore, the use of overlay also helps to lower the barrier-to-entry for software programmers to make use of FPGAs with much higher design productivity. 

\subsection{Providing HW/SW Support}
Some of the researchers have also explored various facilities to support mixed hardware-software designs in a unified languages and run-time environments \cite{so2008unified, lubbers2009ReconOS, fleming2014leap, chung2011coram, andrews2008achieving, agron2009domain} on the hybrid reconfigurable computing systems. For instance, ReconOS operating system \cite{lubbers2009ReconOS} offers unified operating system services for functions executing in software and hardware and a standardized interface for integrating custom hardware accelerators. BORPH \cite{so2008unified} views FPGA programs as UNIX processes that can communicate externally by means of UNIX pipes. CoRAM and LEAP \cite{chung2011coram, fleming2014leap} have investigated memory abstractions for FPGAs and provide a virtualized memory environment to simplify the development. Basically the features provided by these systems can significantly lower the entry barrier for software designers to make use of FPGA acceleration on a hybrid CPU-FPGA computing system. 

\subsection{Reducing FPGA Implementation Time}
Unlike compiling software programs, implementing a hardware design on to an FPGA using standard hardware design tools can take dozens of minutes for smaller designs and upward of days with the largest designs. The disproportionally long run-time dramatically hinders the designers' productivity. To address the lengthy FPGA implementation problem, some of the researchers try to make quality-run-time trade-offs \cite{mulpuri2001runtime, sankar1999trading}, develop novel implementation algorithms\cite{wrighton2003hardware, tessier2002fast, maidee2003fast} and parallelize the implementation tools to reduce the hardware implementation time directly \cite{moctar2014parallel, goeders2011deterministic, altera-pc, xilinx-pc}. Other researches take advantages of the dynamic partial reconfiguration capabilities of modern FPGAs to shorten the run-time by reusing the unchanged part of the design and reducing the design size that needs to be recompiled \cite{frangieh2010PATIS, kao2005benefits, horta2002dynamic, beckhoff2012go}. Yet another group of researchers approach the problem from a higher level, innovating on how these implementation tools are being used from a design methodology's point of view. By using pre-built hard-macros, modular design flows have been explored \cite{lavin2013improving, korf2011automatic, lavin2011HMFlow, lavin2013impact}. While these approaches have significantly reduced the hardware implementation time, they remain at least two orders of magnitude slower when compared to a typical software compilation process.

\subsection{Offering FPGA Debugging Facilities}
Debugging is an essential part of the FPGA design tool chain. However, the traditional FPGA design methodology rely heavily on cycle-accurate simulations for application development and debugging \cite{chipscope, signaltap, certus}. While such simulations are important to understand the low-level operations of FPGA, they are slow, tedious and provide only limited information about the run-time behavior of the design. Most importantly, they are rarely accessible to the software designers without much circuit design experiences. A few debugging tools on top of the latest HLS tools emerged recently \cite{hung2014accelerating, hung2014incremental, panjkov2015hybrid, goeders2014effective}, and they are able to provide kind of software designer oriented debugging on top of the latest HLS based design tools. However, many challenges still exist in these tools such as lack of multiple-clock domain circuit debugging support, limited debugging coverage due to the on-chip block RAM constrain and insufficient hardware-software co-design etc. FPGA debugging facilities that target software designers are still in their infancy. 

\subsection{Automating Design Space Exploration (DSE)}
Hardware design typically involves a labyrinth of architectural parameters and compilation parameters. Fine-tune these design parameters is a slow, error-prone and non-trivial process. Requiring a user to manually explore the design space for an optimized design thus negatively affects the design productivity as well. To address this problem, a number of automatic DSE algorithms have been proposed over the years. Since HLS tools are increasingly being used, previous automatic DSE frameworks were mostly developed on top of the HLS tools \cite{zhong2014design, schafer2012machine, holzer2007design, schafer2012divide, liu2013learning, kurek2014automating}.
 
Since it is difficult to predict the performance and resource consumption of the HLS tools, they typically considered an HLS tool as a black box. A number of generic algorithms were adopted to perform the DSE and customization for better trade-off between performance and resource consumption. The authors in \cite{holzer2007design} adopted a genetic algorithm to the problem of identifying Pareto optimal solutions of time and area design space using HLS. They showed that a complete DSE would take quite a lot of design efforts and a two-stage fitness function could effectively reduce the DSE time while obtaining a reasonable subset of the Pareto optimal solutions. The authors in \cite{schafer2012machine} proposed a machine-learning based predictive model DSE for HLS tools. With a given error threshold, the predictive model avoids time-consuming synthesis and simulation of different HLS synthesis configurations. Compared to a generic simulated annealing algorithm, it is around 2 times faster while achieving similar better results. The authors in \cite{liu2013learning} studied the application of learning based methods to HLS based DSE. Based on Random-Forest learning model, transductive experimental design and randomized selection, the proposed design methods can effectively find an approximate Pareto set of designs. Divide and conquer method was used in \cite{schafer2012divide} and a calibration tree algorithm was used in \cite{kurek2014automating}. While it is even more difficult to predict the FPGA implementation especially the timing information due to the complex and unpredictable placing and routing processes on a piece of irregular hardware design generated using HLS tools, the number of cycles are usually used as the performance metric and timing related metrics such as power and energy consumption are rarely available for these HLS based DSE methods.

\section{Overlay Architectures}
Recently there has been an increased interest in applying the concept of overlay architectures and quite a few works on FPGA overlays have been developed \cite{lysecky2005firm, brant2012ZUMA, grant2011malibu, coole2010intermediate, koch2013efficient, ferreira2011fpga, shukla2006quku, lin2012energy, capalijia2013pipelined, microblaze, nios, cheah2012iDEA, laforest2012OCTAVO, yiannacouras2007exploration, anjam2010vliw,hannig2014invasive, boppu2014compact, yiannacouras2009fine, guy2012VENICE, buciak2007lightweight, liu2004fpga}. By building an advanced computing architecture on top of FPGA devices, the users can program on top of these advanced computing architectures instead of the fine-grained low-level FPGAs. Thus it helps to enhance the designers' productivity from multiple aspects including raising the abstraction level of FPGA design entry, facilitating HW/SW co-design and FPGA debugging, reducing the implementation time for mapping applications to FPGAs and simplifying the design optimization. Therefore, it has become one of the most promising methods to make FPGA programming accessible to software designers. In this section, various types of FPGA overlays that have been explored in the past decade will be presented.

\subsection{Virtual FPGA Overlay}
One of the most easiest to understand categories of overlays are virtual FPGAs \cite{lysecky2005firm, brant2012ZUMA, grant2011malibu, coole2010intermediate, koch2013efficient}. They are built either virtually or physically on top of the off-the-shelf FPGA devices. These overlays have different configuration granularity but typically have coarser configuration granularity than a typical FPGA device. By providing an additional layer, they can be used to improve application portability and compatibility over FPGAs of different parts or even different vendors. Furthermore, because of the coarser-grained configurable granularity, implementing designs on such overlay is relatively easier than on a fine-grained device. However, the additional layer imposes restrictions on the underlying fabrics' capability and usually results in moderate hardware overhead and timing degradation.

The authors in \cite{lysecky2005firm} developed a relatively fine-grained virtual FPGA as firm cores expressed using structural VHDL. The virtual layer provides effective portability yet incurs relatively high performance and hardware overhead. Through the utilization of LUTRAMs as reprogrammable MUXs and LUTs, the authors in \cite{brant2012ZUMA}could further reduce the resource consumption considerably while maintaining the routability and mapping efficiency. In \cite{grant2011malibu}, Grant et al. proposed a time-multiplexed virtual FPGA CAD framework MALIBU. The virtual FPGA adopted in MALIBU has both fine-grain and coarse-grain processing elements integrated into each logic cluster and can be used to reduce the compilation time significantly with moderate timing penalty. Coole and Stitt also proposed another island-style coarse-grained overlay called Intermediate Fabric \cite{coole2010intermediate}. It uses coarse-grained operators such as adders instead of logic clusters and routes data through 8 to 32 bit buses achieving both portability and fast compilation. Koch et al. developed a fine-grained FPGA overlay in \cite{koch2013efficient} to implement customized instructions on FPGAs. It allows the execution of a portable application consisting of a program binary and an overlay configuration in a completely heterogeneous environment. 

\subsection{Coarse-Grained Reconfigurable Array Overlay}
Another category of overlay architecture employed is coarse-grained reconfigurable array (CGRAs) \cite{ferreira2011fpga, kissler2006dynamically, shukla2006quku, lin2012energy, capalijia2013pipelined} which is essentially an array of connected processing elements with limited computing capability and reconfigurability. The use of CGRAs provides an efficient trade-off between flexibility of software and performance of hardware especially for compute intensive applications as demonstrated by numerous earlier CGRAs on application-specific integrated circuit (ASIC) \cite{tessier2001reconfigurable, compton2002reconfigurable}.

In one of the earlier works in this area \cite{shukla2006quku}, a customized CGRA overlay called QUKU was developed for DSP algorithms. It featured a two-level configuration including a high-speed configuration and a low-speed configuration. The high-speed configuration was used for operator reuse within an application and the low-speed reconfiguration was used for optimization between different applications. Due to the limited flexibility, it targeted only a limited number of DSP algorithms. Kissler et al. developed WPPA (weakly programmable processor array), a VLIW architecture based parameterizable CGRA overlay \cite{kissler2006dynamically}. It featured an interconnection wrapper unit for each processing element (PE) that could be used for dynamic topology customization. In \cite{ferreira2011fpga}, Ferreira et al. proposed a heterogeneous CGRA overlay with a global multi-stage interconnection on FPGA. This CGRA overlay is essentially an array of heterogeneous mathematical operators and there are no local register files near each operators except the pipeline registers. The simplicity of the overlay allows very fast application mapping. Compiling applications onto the overlay takes only milliseconds for smaller DFGs. The authors in \cite{capalijia2013pipelined} built a generic high speed mesh CGRA overlay. This work particularly focused on the overlay implementation. By using the elastic pipeline technique, it achieved high implementation frequency and thus high throughput. It adopted a data-driven execution flow and was suitable for smaller pipelined DFG execution. The authors in \cite{jain2015efficient} proposed an island-style CGRA overlay that is constructed centering the primitive FPGA DSP blocks to achieve high-frequency implementation and high throughput result. Previous CGRA overlays have demonstrated the potential computing capability and promising compilation speed, but there are still little work on using the overlay for loop kernel acceleration on a hybrid CPU-FPGA computing system. 

\subsection{Processor-Like Overlays}
A third category of overlay is processor-like design including soft general purpose processor \cite{microblaze, nios, cheah2012iDEA, laforest2012OCTAVO, yiannacouras2007exploration}, massively parallel processing arrays (MPPA) \cite{anjam2010vliw, hannig2014invasive, boppu2014compact}, many-core processor \cite{lebedev2010MARC} and GPUs \cite{jeffrey2011potential}. The main concerns of using the overlays in the third category are compatibility and usability of the overlay from a user's perspective. With the processor-like overlay, the users can essentially program FPGA by writing software programs. Consequently, there is almost no barrier for software designers to make use of FPGAs. To provide the required performance, these overlay architectures should remain configurable specifically to applications with ample parallelism.

General purpose soft processor is one of the most widely used on FPGA and many such processors have been developed from both academia and industry \cite{microblaze, nios, cheah2012iDEA, laforest2012OCTAVO, yiannacouras2007exploration}. Microblaze and Nios \uppercase\expandafter{\romannumeral2} are two commercial embedded soft processors from Xilinx and Altera \cite{microblaze, nios}. They adopt Reduced Instruction Set Computing (RISC) ISA and allow intensive customization including instruction set and the major architectural parameters such as cache architecture. Moreover, the micro-architectures of the processors are specially optimized for their own FPGA devices as well for higher performance. In academia, a number of soft processors have also been developed \cite{cheah2012iDEA, laforest2012OCTAVO}. Cheah et al. developed a lightweight soft processor that made best use of underlying Xilinx primitive DSP48E1 slices for a load-store processor. In the work \cite{laforest2012OCTAVO}, the authors also explored the potential of the underlying FPGA fabrics and developed a soft processor named Octavo. The processor was highly pipelined and could work at 550MHz on Stratix \uppercase\expandafter{\romannumeral4}. Meanwhile, it is also highly parameterizable and customizable. In the work \cite{yiannacouras2007exploration}, the authors concentrated on application-specific customization of the soft processors and exhibited promising performance speedup as well as resource saving through the customization.

Beyond these processors, a number of VLIW soft processors \cite{anjam2010vliw,hannig2014invasive, boppu2014compact}, vector processors \cite{yiannacouras2009fine, guy2012VENICE} and specialized processors \cite{buciak2007lightweight, liu2004fpga} have also been explored on FPGAs in the past decade. Boppu and Hanning et al. a VLIW architecture based parameterizable MPPA overlay \cite{hannig2014invasive, boppu2014compact}. Each processing element in the MPPA is basically a simplified VLIW core executing sequential instructions while the PEs can execute in parallel. Yiannacouras et al. explored the use of a fine-grained scalable vector processor for code acceleration in embedded systems \cite{yiannacouras2009fine}. Later in \cite{guy2012VENICE}, Severance and Lemieux proposed a soft vector processor named VENICE to allow easy FPGA application development. It accepts simple C program as input and execute the code on the highly optimized vector processor on the FPGA for performance. The works in \cite{buciak2007lightweight, liu2004fpga} mainly focused on optimization of network processor overlays on FPGAs.  

In the work of MARC, Lebedev et al. explored the use of a many-core processor template as an intermediate compilation target \cite{lebedev2010MARC}. In this work, they have demonstrated the improved usability while highlighting the need for customizing computational cores for the sake of performance and resource consumption. Finally, a GPU-like overlay was proposed in \cite{jeffrey2011potential} and this work demonstrated the good performance while maintaining a compatible programming model for the users.

\section{Overlay Customization}
Not only does the overlay offer desirable software-programmable fabrics on top of physical FPGAs, it also takes advantage of the inherent programmability of the physical FPGA allowing the overlay to be specifically customized to an application or a group of applications for the sake of both performance and energy efficiency. While the application specific customization requires to navigate through a labyrinth of design parameters, it is almost impossible for a user to manually explore such a vast design space. Thus automatic overlay customization is critical to the adoption of the advanced computing architectures. 

On top of the coarse-grained FPGA overlay \cite{coole2010intermediate}, Coole and Stitt proposed to provide the overlay with limited flexibility instead of full configurability specifically to a group of design \cite{coole2015adjustable}. With this customization, the area overhead was reduced significantly. While most of the virtual FPGAs are typically developed for design portability and thus aim to provide a relatively general architecture to a broad range of applications, there are few works focusing on the application specific customization. 

Soft processors are the most widely used overlay architecture and there have been a great number of frameworks and design methods from both industry and academia developed for application specific optimization \cite{nios, microblaze,lodi2003pipelined, gries2004methods, leon, itoh2000peas, yiannacouras2005microarchitecture, dimond2005custard, chattopadhyay2006automatic}. The works in \cite{lodi2003pipelined, gries2004methods, nios, microblaze, leon} typically relied on a parametrized cores allowing a limited aspects of architectural parameters to be tuned for the target applications. The design space is highly constrained, but the exploration can be relatively fast. Most importantly, the well-tuned parametrized cores typically provided efficient hardware implementation. While the works in \cite{itoh2000peas, yiannacouras2005microarchitecture, dimond2005custard, chattopadhyay2006automatic} provided a system view of the soft processor customization based on architectural description languages providing a complete solution including the creation of the customized compilers, instruction set simulators, cycle accurate simulators and so on. A survey of the soft processor customization can be found in \cite{chattopadhyay2013ingredients, galuzzi2011instruction}. 

Customizing the CGRA specifically for an application or a domain of application provides promising performance improvement while saving the hardware resource at the same time as demonstrated in CGRA work targeting ASIC design \cite{compton2001totem, zhou2014application, miniskar2014retargetable}. While CGRA customization on ASIC is relatively limited due to the tape-out cost, CGRA overlays allow more intensive architectural customization providing just enough hardware to the target application or application domains because of the FPGA's inherent programmability. In \cite{bondhugula2007automatic}, the authors formalized the loop acceleration on a regular processing array overlay on FPGA. They focused on the hardware resource constrain, IO bandwidth constrain and the loop parallelism partition while processing architectural design parameters were not included. In \cite{lin2012energy}, Lin and So proposed a soft CGRA overlay for rapid compilation high-level loops with fully unrolling to the overlay. In particular, they demonstrated that customizing the overlay connection between PEs on a per-application basis improves the energy-efficiency in the expense of longer tool run time.

