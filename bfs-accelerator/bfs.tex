%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Simple Sectioned Essay Template
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing essay content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{article} % Default font size is 12pt, it can be changed here

\usepackage{geometry} % Required to change the page size to A4
\geometry{a4paper} % Set the page size to be A4 as opposed to the default US Letter
\usepackage{listings} % Insert program segments in the text
\usepackage{float} % Allows putting an [H] in \begin{figure} to specify the exact location of the figure
\usepackage{wrapfig} % Allows in-line images such as the example fish picture
\usepackage[per-mode=fraction]{siunitx}
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{graphicx}
\usepackage{multirow}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{dblfloatfix}
\usepackage{xspace}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[table]{xcolor}
\usepackage{cite}
\usepackage{url}

\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}

\linespread{1.2} % Line spacing
%\setlength\parindent{0pt} % Uncomment to remove all indentation from paragraphs

\graphicspath{{./figures/}} % Specifies the directory where pictures are stored

\begin{document}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

\HRule \\[0.4cm]
{ \huge \bfseries Strategetic Optimization for BFS Acceleration on FPGAs}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]

\begin{minipage}{0.4\textwidth}
    \centering {Cheng Liu} \\ 
    \vspace{2em}
    \centering {\large \today}
\end{minipage}

\end{titlepage}

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\tableofcontents % Include a table of contents

%\newpage % Begins the essay on a new page instead of on the same page as the table of contents 

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------
\section{Introduction} % Major section
Graph is a common data representation in a broad domains of applications such 
as social networks, bioinformatics, metabolic networks and computer networks. 
As the graph grows in scale in the big data era, graph processing becomes 
increasingly costly and accelerating the widely used building components 
such as Breadth-first search (BFS) is of vital importance for high-performance 
graph processing. 

BFS is notoriously difficult for accelerating on parallel computing architectures 
because of the irregular memory access and the low computation-to-memory ratio. 
These characteristics essentially make BFS a memory bandwidth bounded task and 
challenging for accelerating. To approach this challenge, a number of research 
have been performed targeting on various platforms including multicore processors, 
GPUs \cite{liu2015enterprise}, FPGAs \cite{attia2014cygraph, betkaoui2012reconfigurable, 
umuroglu2015hybrid, oguntebi2016graphops, engelhardt2016gravf}, ASICs 
\cite{ham2016graphicionadoand} and distributed systems over the past few years. 

With the increased interest on energy efficient computing systems, 
FPGAs gains increasing popularity and is rapidly moving forward to 
main-stream computing system and gets adopted in more data centers. 
Many previous work also demonstrated that building BFS accelerators 
on FPGAs can provide competitive performance over multi-core CPUs 
on top of the energy efficiency. In this work, we thus try to explore 
BFS accelerating on FPGAs and we 
argue that FPGA is suitable for BFS acceleration mainly for two reasons. 
First of all, FPGA allows specific memory access infrastructures to be 
built to fit for various memory access patterns including customized caching, 
streaming and random memory access. Secondly, BFS is memory bound and suffers 
relatively long external memory access latency. As a result, it turns to be a 
good fit to FPGAs with ample parallelism but relatively slow clock speed.

BFS will be briefly explained here. Some concepts such as frontier will be 
introduced here as well.

Previous BFS acceleration on FPGA work mainly focused on developing parallel 
hardware architectures to improve the resulting performance. However, the inherent 
memory bound characteristic of BFS dramatically limits the benefits brought by more parallel 
processing logic. In this work, we focus on strategetic optimizations which aims to 
reduce the amount of memory access and improve the memory bandwidth utilization 
to directly alleviate the bottleneck of the BFS accelerators on FPGAs and thus 
enhance the resulting performance. Four BFS optimization strategies 
are developed to improve the memory bandwidth utilization of the BFS accelerator. 

\begin{itemize}
	\item The BFS is divided into two phases. In the first phase, the frontier is 
		inspected from the vertex level information with complete sequential 
		memory access. In the second phase, it traverses the frontier just as the 
		conventional level based BFS. Compared to the conventional level based BFS, 
		the frontier is no longer a shared writing queue among the paralell traverse 
		processing logic and it ensures no duplicated vertices in the frontier queue. This 
		strategy thus avoids either complex unique processing of the frontier or 
		redudant frontier vertices processing. Although additional inspection stage is 
		needed, it brings just sequential memory access and can be very efficient.
		Essentially this strategy improves the memory bandwidth utilization.

	\item The frontier vertices are classified into four groups based on 
		its vertex degree and each group of the frontier vertices will be 
		processed with specially customized logic. Basically frontier 
		vertices with higher degree will be handled by processing elements 
		with burst memory access support, while low-degree vertices will be 
		passed to process elements with just simple random memory access. 
		This strategy helps to improve the memory bandwidth utilization as 
		well as balancing the processing time of different vertices.

	\item A typical top-down based BFS is efficient when the frontier size is small. However, 
		the vertices in the same frontier may have the same neighbors. When they are 
		processed in parallel, a large amount of redundant traverse will be incurred at BFS 
		level with larger frontier size. This problem gets worse for the graphs with 
		small-world property whose BFS frontier size scales with power law. A bottom-up BFS 
		can be more efficient for BFS iterations with larger frontier size. Thus a hybrid top-down 
		and bottom-up BFS is implemented. With a relatively BFS mode switching metric, this hybrid 
		BFS can reduce the amount of memory access significantly.  
		
	\item Real-world graphs have small world property and a small portion of the vertices have high 
		degree. These high-degree vertices may be referenced many times during the traverse. With this 
		observation, the high-degree vertex traversal status is cached on FPGA. Whenever a status of 
		vertex needs to referenced during the traverse, the processing elements will check the 
		cache first. High degree vertex status cached on-chip will thus help to avoid the repeated 
		memory access and improves the memory bandwidth utilization eventually. 
\end{itemize}

The organization of the paper goes as follows. Section 2 presents the background of the BFS 
algorithms and related work on BFS acceleration. Section 3 gives the overview of the 
proposed BFS accelerator. Section 4 details the optimization strategies and the corresponding 
implementations. Section 5 shows the experimental results and analysis. Section 6 concludes 
this work.

\section{Background and Related Work}
This section will firstly introduce the background of the BFS algorithms and then 
review previous BFS acceleration work.

\subsection{Background}
BFS is a widely used graph traversal algorithm in many applications. 
It traverses the graph by processing all vertices with the same distance from the 
source vertex iteratively. The set of vertices which have the same distance from the 
source is defined as frontier. The frontier that is under analysis in the BFS iteration 
is named as current frontier while the frontier that is inspected from current frontier 
is called next frontier. By inspecting only the frontier, BFS can be implemented efficiently 
and thus the frontier concept is utilized in many BFS implementations.

BFS algorithm can be formalized as follows. Assume $G$ is a graph with vertex 
set $V$ and edge set $E$, BFS finds a shortest path from a source vertex
$v_s \in V$ to all the other vertices in the graph $G$. For each vertex $v \in V$, 
BFS will output a level value $l$, indicating its distance from $v_s$ ($v$ can be accessed 
from $v_s$ by traveling through $l - 1$ edges). 

Algorithm \ref{alg:level-bfs} presents a level synchronized BFS algorithm. It has been utilized in many 
previous BFS accelerators. More explanation will be added here. 
\begin{algorithm}
	\caption{Level Synchronized BFS Algorithm} \label{alg:level-bfs}
	\begin{algorithmic}[1]
		\Procedure{BFS}{}
		\State $level[v_k] = -1$ where $v_k \in V$
		\State $level[v_s] = 1$
		\State $current\_frontier \gets v_s$
		\State $current\_level = 1$
		\While {$current\_frontier$ not empty} 
		\For{$v \in current\_frontier$}
		\State $S = {n \in V | (v, n) \in E}$
		\For {$n \in S$}
		\If {$level[n] == -1$}
		\State $level[n] \gets current\_level + 1$
		\State $next\_frontier \gets n$
		\EndIf
		\EndFor
		\EndFor
		\State $current\_level = current\_level + 1$
		\State Swap $current\_frontier$ with $next\_frontier$
		\EndWhile
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\subsection{Related Work}
to be added.


\section{BFS Optimization Strategies}
The modified BFS algoirithm is presented in \ref{alg:modified-bfs}.
BFS optimization strategies wll be detailed in this section.
\begin{algorithm}
	\caption{Modified BFS Algorithm} \label{alg:modified-bfs}
	\begin{algorithmic}[1]
		\Procedure{BFS}{}
		\State $level[v_k] = -1$ where $v_k \in V$
		\State $level[v_s] = 0$
		\State $current\_level = 0$
		\State $frontier \gets v_s$

		\While {$frontier$ not empty} 

		\For{$v \in V$}
		\If{$level[v] == current\_level$}
		\State $frontier \gets v$
		\EndIf
		\EndFor

		\For{$v \in frontier$}
		\State $S = {n \in V | (v, n) \in E}$
		\For {$n \in S$}
		\If {$level[n] == -1$}
		\State $level[n] \gets current\_level + 1$
		\EndIf
		\EndFor
		\EndFor
		\State $current\_level = current\_level + 1$
		\EndWhile
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


\section{Proposed BFS Accelerator}
The BFS accelerator overview and hardware modules  developed for the corresponding
BFS optimization strategies will be detailed here.

\section{Experiments}
\subsection{Experiment Setup}
\subsection{Graph Benchmark}
\subsection{Results}
\begin{itemize}
	\item performance improvements and resource overhead of the optimization strategies
	\item Reduced communication with the optimized strategies
	\item Runtime distribution analysis 
\end{itemize}

\section{Conclusion}
to be added.

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------
\bibliographystyle{plain}
\bibliography{refs}
%----------------------------------------------------------------------------------------

\end{document}
