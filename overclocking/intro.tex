\section{Introduction} \label{sec:intro}
%Recent years have seen great success of machine learning especially 
%convolutional neural networks (CNNs) on massive fields such as 
%image classification, video surveillance, speech recognition, 
%and robot vision. 
The widespread adoption of CNNs motivates the 
continuous optimization of CNN accelerators for higher 
performance and energy efficiency. 
Numerous approaches from various 
angles have been proposed and explored \cite{EIE_han_2016} \cite{deepburing_12}. 
Particularly, many of them such as 
low-precision quantization \cite{Hwang2014_17} \cite{Matthieu2014_8} 
and approximate computing \cite{Approximate_Multiplier_31} \cite{Approximate_32}
have been demonstrated to 
be able to improve the performance or lower the power consumption of the CNN 
accelerators significantly. In spite of the computing errors caused by these approaches, 
the prediction accuracy loss of the neural networks is negligible according to the prior works \cite{deep_compress_han_2015}.
One of the key reasons can be attributed to the inherent fault-tolerance of 
the neural networks, which means that minor variations on the 
computing of neural networks typically will not lead to considerable 
difference in terms of prediction accuracy. This 
feature essentially prevents the propagation of 
the minor computing errors to the neural network prediction errors. 
Therefore, the corresponding approaches that allow design trade-off 
between computing accuracy and performance can be applied to CNN 
accelerator optimization.

Inspired by this observation, we notice that overclocking, which 
allows the circuit running at higher clock frequency with minor 
timing violations, can also compromise between performance 
and computing accuracy. When applying overclocking to CNN accelerators, 
it can potentially improve the performance and energy 
efficiency with minor prediction accuracy loss.
Compared to prior optimization approaches, overclocking brings 
multi-folded unique advantages especially to the FPGA based CNN 
accelerators. 


As demonstrated in \cite{Caffeine_6} \cite{EIE_han_2016}, convolution is usually 
computing-bound and it is the most time-consuming part of the CNNs, while 
full connection layers are mostly memory-bound. Particularly, it can be found that 
newer neural networks such as ResNet and DarkNet involve more 
convolution layers and less full connection layers. Thus, convolution neural 
networks are mostly constrained by the computing capability of the accelerators. 
It is known that the frequency of the CNN 
accelerators determines the operation speed directly. However, 
the clock on FPGAs usually ranges from 150 MHz to 300 MHz and 
remains much lower compared to the ASIC designs. The 
bandwidth of DRAM on FPGAs and ASICs does not have any 
clear gap \cite{asic_fpga}. Thus, computing of the FPGA based CNN 
accelerators is more stringent and becomes the major 
performance bottleneck. Overclocking can greatly alleviate this 
problem without redesigning the CNN accelerators and is 
mostly orthogonal to the other optimizations. 

Another advantage brought by overclocking is the higher 
energy efficiency. Typically the overall power of the 
FPGA based CNN acceleration system consists of kernel accelerator power 
and background power. The kernel accelerator power 
roughly scales with the clock frequency and performance, 
so overclocking will not incur more energy consumption. 
The background power changes little with clock frequency. 
Taking both parts into consideration, overclocking improves the energy efficiency.

To deploy overclocking on FPGA based CNN accelerators, there are also several
challenges that need to be addressed. Timing errors caused by overclocking 
may probably located on the critical paths which may spread across the 
design and change with the data, while the critical path can be
affected by the work environment such as the temperature 
and input data, it may deteriorate or vary at runtime \cite{Paceline_15}. 
As a result, the influence of overclocking timing 
errors on the computing of CNNs is rather complex. It may lead to
computing errors when the computing data paths are affected or system stall 
when some critical control signals get affected. To ensure robust computing 
on the overclocked CNN accelerators, all the errors must be detected and 
handled appropriately. In this case, different fault detection strategies 
and fault recovery strategies should be adapted accordingly. 

Overclocking essentially focuses on relaxing the
design constraints and the safety margins. A number of works \cite{Razor} 
\cite{uht2004going} adopted “better than worst case design” to allow the system 
to work aggressively and recover from timing 
errors \cite{austin2005opportunities} with additional error checkers. 
They demonstrated that the benefits
brought by removing the safe margin outweigh the cost
of monitoring and recovering from errors. 
The authors in \cite{overclock_3} explored the design trade-off 
between performance and accuracy on FPGAs through overclocking. 
This work demonstrated the potential of applying the trade-off on 
some image processing applications. In \cite{brant2013safe}, the authors 
proposed a safely overclocked CGRA design. Recently, Wang etc. in 
\cite{deng2015retraining} and \cite{wang2017resilience} investigated 
the use of overclocking on CNN accelerators, but they mainly targeted at 
the clock frequency tuning with complex timing models and explored 
only small neural networks due to the timing-consuming simulation.

In this work, we explored the use of overclocking on FPGA based 
CNN accelerators. By taking advantage of the inherent fault-tolerance 
of neural networks as well as the FPGA reconfiguration capability, we aim to 
boost the CNN accelerator clock and mitigate 
the negative influence of the timing errors with negligible cost. 
The contributions of this work is concluded as follows:

\begin{itemize}
	\item We proposed to apply overclocking on FPGA based CNN accelerators 
		to alleviate the stringent computing bottleneck and improve the 
		overall energy efficiency. 

	\item For all the possible negative influence of 
		overclocking, we proposed a series of error detection 
		and recovery mechanisms to ensure resilient neural network execution. 

	\item With comprehensive experiments, we demonstrated that the use 
		of overclocking can improve the accelerator performance and energy 
		efficiency significantly with negligible prediction accuracy loss.
\end{itemize}

The paper is organized as follows. Section II motivates the use of overclocking. 
Section III presents the use of overclocking on FPGA based CNN 
accelerators with additional error detection and recovery. 
Section IV performs comprehensive experiments and demonstrates the benefits 
of using overclocking. Section V concludes this work. 


