\section{Conclusion} \label{sec:Conclusion}
The neural network computing on the CNN accelerators 
can be different from that computed on GPPs when the 
CNN accelerators get overclocked. When deploying the offline
trained models to these accelerators, the neural network model 
prediction accuracy will drop a lot. In this work, we propose an 
on-accelerator training framework to address this problem.
Then build the training framework based on Caffe on a 
hybrid CPU-FPGA architecture. According to our 
experiments, both the top1 and top5 prediction 
accuracy improves significantly in general and the improvement goes 
up to 13.7\% and 11.6\% respectively when compared to the 
offline trained model. The performance and EDP can also improves 
significantly due to overclocking.

%\appendix
%\section{Acknowledgement}

%\begin{acks}
%  The authors would like to thank Sam Ho for providing the suggestions on
%  HLS design debugging and optimization as well as the SDAccel usage. 

%\end{acks}
