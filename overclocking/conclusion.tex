\section{Conclusion} \label{sec:Conclusion}
The neural network computing on the CNN accelerators 
can be different from that computed on GPPs when the 
CNN accelerators have approximate arithmetic operations, 
get overclocked or suffer soft errors. When deploying the offline
trained models to these accelerators, the neural network model 
prediction accuracy can drop a lot. In this work, we propose an 
on-accelerator training framework to address this problem.
and then build the training framework based on Caffe on a 
hybrid CPU-FPGA architecture. With the on-accelerator training 
framework, we perform three 
case studyies on CNN accelerators with approximate arithmetic unit, 
overclocking and soft errors. According to our 
experiments on the case studies, both the top1 and top5 prediction 
accuracy improves significantly in general and the improvement goes 
up to 14.4\% and 16.1\% respectively when compared to the 
offline trained model. The disadvantage is the 
much longer training time.

%\appendix
%\section{Acknowledgement}

%\begin{acks}
%  The authors would like to thank Sam Ho for providing the suggestions on
%  HLS design debugging and optimization as well as the SDAccel usage. 

%\end{acks}
