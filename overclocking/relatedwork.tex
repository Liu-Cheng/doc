\section{Related Work} \label{sec:relatedwork}
The computing on CNN accelerators may vary due to various reasons 
such as overclocking.
Overclocking is a technique to increase the circuit operating speed 
without redesigning, but it will cause timing errors \cite{overclock_3}, \cite{Razor}.  
So the offline trained model will suffer considerable prediction 
accuracy loss when it is deployed directly. Therefore, they should be considered in the 
neural network training.
There are also efforts spent to use FPGAs for training. 
Caffeine\cite{Caffeine_6} provided a general CNN accelerator design and integrated it with
the training framework Caffe. Caffeinated FPGA\cite{DiCecco_4} implemented FPGA kernels
for both forward propagation and backward propagation. It can also be used in Caffe and allows for
both training and inference. However, these work focus on the performance optimization.
They also support on-accelerator training, but they do not take the computing
variation of the CNN accelerators into consideration. 

