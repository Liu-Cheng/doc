\section{Automatic nested loop acceleration design framework} \label{sec:acc-framework}
By using a regular SCGRA overlay built on top of the physical FPGA devices, 
we have developed an automatic nested loop acceleration framework 
as shown in \figref{fig:framework}. It targets a hybrid CPU-FPGA
computing system where the FPGA focuses on the compute intensive loop kernel and CPU handles the
rest of the application. To that end, a standard software compilation routine is included to
produce binary code for the CPU. The framework also has a fast and common SCGRA based accelerator
generation path which is able to make use of pre-built bitstream to generate FPGA
loop accelerator bitstream during the design iterations \cite{scgra}. Meanwhile, it consists of a
relatively slow yet per-loop based accelerator customization and implementation path. It
automatically tunes the design parameters 
including overlay architectural parameters, compilation options as well as communication between the
FPGA accelerator and host processor specifically to a user application under the user constraints
such as hardware resource and energy consumption budgets. When the optimal design 
parameters are determined, SCGRA overlay based FPGA accelerator HDL models and drivers will be
generated. Afterwards, the drivers will be used by the software compilation while the FPGA
accelerator will be implemented and stored in the accelerator library which can be reused by the
fast accelerator generation route.

\begin{figure}[tb]
\center{\includegraphics[width=0.85\linewidth]{framework}}
\caption{Automatic nested loop acceleration framework}
\label{fig:framework}
\end{figure}

\subsection{SCGRA based FPGA accelerator}
\figref{fig:scgra-acc} shows the design of a typical SCGRA overlay 
based FPGA accelerator. In the accelerator, on-chip
memory i.e. IBuf and OBuf are used to buffer the communication 
data between the host CPU and 
the accelerator. A controller is also presented in hardware 
to control the operations of the accelerator as well as
memory transfers. The SCGRA, which is the kernel computation fabric,
consists of an array of PEs and it achieves the computation 
task through the distributed control words stored in each PE. The AddrBuf 
stores all the valid IO buffer accessing addresses of the computation. 

\begin{figure}[tb]
\center{\includegraphics[width=0.8\linewidth]{scgra-accelerator}}
\caption{SCGRA overlay based FPGA accelerator}
\label{fig:scgra-acc}
\end{figure}

\figref{fig:pe} shows the current implementation of a 
PE template that features an optional load/store path. 
At the heart of the PE is an ALU, which is supported by a multi-port 
data memory and an instruction memory. Data memory stores intermediate data during the computation
while instruction memory stores all control words that determines the action of the PE. 
In addition, a global signal from the AccCtrl block controls the start/stop of all PEs in the array.

\begin{figure}[tb]
\center{\includegraphics[width=0.85\linewidth]{pe}}
\caption{Fully pipelined PE structure. Each PE can be connected to at most 4 neighbours.}
\label{fig:pe}
\end{figure}

\subsection{Loop execution on the FPGA accelerator}
\figref{fig:group-dfg} illustrates how the loop is executed 
on the FPGA accelerator. First of all, 
data flow graph (DFG) is extracted from the loop and then it 
is scheduled on to the SCGRA overlay based FPGA accelerator. 
Depending on how much the loop is unrolled and transformed 
to DFG, the DFG may be executed repeatedly until the end of 
the original loop. In addition, data transfers for 
multiple executions of the same DFG are batched into groups 
as shown in \figref{fig:group-dfg}. On the one hand, this technique is used to 
reduce the number of batching, which further helps to amortize 
the initial communication cost. On the other hand, it also 
results in larger on-chip memory overhead. The proposed customization framework 
can be used to make the right design choices to achieve an optimal design. 

\begin{figure}[tb]
\center{\includegraphics[width=0.7\linewidth]{group-dfg}}
\caption{Loop, group and DFG. The loop will be divided into 
groups. Each group will be partially unrolled and the unrolled part will be 
translated to DFG. IO transmission between FPGA and host CPU is performed 
in the granularity of a group.}
\label{fig:group-dfg}
\end{figure}

\subsection{SCGRA overlay compilation}
With pre-built SCGRA overlay, the corresponding FPGA accelerator can be generated rapidly, which
is also the basis of the high-productivity loop accelerator design framework.
\figref{fig:detailed-compilation} presents the detailed SCGRA overlay compilation. 
With the specified loop unrolling factor, DFG is generated and scheduled to the SCGRA overlay of the accelerator. 
After the scheduling, control words are extracted, and they can 
further be integrated into the pre-built FPGA accelerator bitstream creating 
the final FPGA loop accelerator bitstream. The compilation process typically completes in a few
seconds as illustrated in \cite{scgra}. This compilation process is particularly useful during the
design iterations of an application when an initial implementation is done and minor modification is
required. 

\begin{figure}[tb]
\center{\includegraphics[width=0.75\linewidth]{detailed-compilation}}
\caption{Rapid SCGRA overlay compilation}
\label{fig:detailed-compilation}
\end{figure}


