\section{Experiments and results} \label{sec:result}
%The experiments mainly include two parts. In the first part, we 
%analyze the implementations of the SCGRA overlay based FPGA accelerators with 
%different configurations to demonstrate the regularity of the 
%SCGRA overlay based FPGA accelerators. In the second part, we benchmark the 
%efficiency and quality of the proposed customization framework.
In the experiments, we measured the time needed to customize the loop accelerators and compared the
performance of the resulting accelerators to that of an hard ARM processor. 

\subsection{Experiment setup}
The customization runtime was obtained using a computer with Intel(R) Core(TM) 
i5-3230M CPU and 8GB RAM. Zedboard which has an ARM processor and 
an FPGA was used as the computation system. PlanAhead 14.7 was used for the SCGRA overlay based 
design. The customized overlay implementations on Zedboard run at 250MHz. To perform the
customization, $\epsilon$ is set to be 0.05 and all the resource on Zedboard is set to be the
resource constraint. Software runtime is obtained from ARM processor of Zedboard.  

In this work, we take four applications including Matrix Multiplication (MM), 
FIR, Kmean(KM) and Sobel Edge Detector (SE) as our benchmark. The 
configurations of the benchmark are detailed in \tabref{tab:benchmark-config}. 

\begin{table}[tb]
    \scriptsize
    \centering
    \caption{Benchmark Configurations \label{tab:benchmark-config}}{
        \begin{tabular}{l|l|l}
            \hline
            Benchmark & Parameters & Loop Structure \\ \hline
            MM & Matrix Size(100) & $100 \times 100 \times 100$ \\ \hline
            FIR & \tabincell{l}{\# of Input (10000) \\ \# of Taps+1 (50)} & $10000 \times 50$ \\ \hline
            SE & \tabincell{l}{ \# of Vertical Pixels (128) \\ \# of Horizontal Pixels (128)} & $128
            \times 128 \times 3 \times 3$ \\ \hline 
            KM & \tabincell{l}{\# of Nodes(5000) \\ \# of Centroids(4) \\ \# of Dimensions(2)} &
            $5000 \times 4 \times 2$ \\ \hline  
        \end{tabular}
    }
\end{table}


%\subsection{SCGRA Overlay Implementation Analysis}
%In order to analyze the overhead and power of the SCGRA overlay 
%based FPGA accelerators, we had three groups of accelerators 
%(SCGRA1, SCGRA2, SCGRA3) implemented on Zedboard. The configurations 
%are detailed in \tabref{tab:config}. Despite of the diverse 
%configurations, all the implementations could meet 200MHz 
%timing constrain. With this timing constraint, 
%hardware overhead and power consumption are analyzed, which are described 
%in the following sub sections.
%\begin{table}[tb]
%    \small
%    \centering
%    \caption{SCGRA Based FPGA Accelerator Configuration \label{tab:config}}{
%        \begin{tabular}{c|c|c|c|c|c}
%            \hline
%            Group & Size & \tabincell{c}{Inst. \\ Rom} & 
%            \tabincell{c}{Data \\ Mem} & \tabincell{c}{IBuf \\ /OBuf} & 
%            \tabincell{c}{Addr \\Buf} \\ \hline
%
%            SCGRA1 & \tabincell{l}{2x2, 3x2, \\ 3x3, 4x3, \\ 4x4, 5x4} & 
%            1kx72 & 256x32 & 2kx32 & 4kx16\\ \hline
%
%            SCGRA2 & \tabincell{l}{2x2, 3x2, \\ 3x3, 4x3, \\4x4} & 
%            2kx72 & 256x32 & 2kx32 & 4kx16\\ \hline
%
%            SCGRA3 & \tabincell{l}{2x2, \\ 3x2, \\ 3x3 } &  
%            4kx72 & 256x32 & 2kx32 & 4kx16\\ \hline
%        \end{tabular}
%    }
%\end{table}
%
%\subsubsection{Hardware Overhead}
%\figref{fig:SCGRA-Overhead} shows the relation between 
%the four types of hardware resource overhead and SCGRA 
%overlay size. It can be found that FF, LUT and DSP overhead 
%do not change much with the memory configurations and they 
%present good linearity to the overlay size, thus they can be 
%estimated with linear models. BRAM overhead depends 
%on both the overlay size and the memory configurations, 
%and single variable linear model will not work for the estimation.
%Fortunately, it can be calculated precisely with the memory 
%configurations. 
%
%\begin{figure}[tb]
%    \subfloat[\label{fig:FF-Overhead}]{%
%      \includegraphics[width=0.22\textwidth]{FF-Overhead}
%    }
%    \subfloat[\label{fig:LUT-Overhead}]{%
%      \includegraphics[width=0.22\textwidth]{LUT-Overhead}
%    }
%    \hfill
%    \subfloat[\label{fig:DSP-Overhead}]{%
%      \includegraphics[width=0.22\textwidth]{DSP-Overhead}
%    }
%    \subfloat[\label{fig:BRAM-Overhead}]{%
%      \includegraphics[width=0.22\textwidth]{BRAM-Overhead}
%    }
%    \caption{Relation between the accelerator overhead and overlay size, 
%    (a) FF overhead, (b) LUT overhead, (c)DSP overhead, (d)BRAM overhead}
%    \label{fig:SCGRA-Overhead}
%\end{figure}
%

%\subsubsection{Power Consumption}
%According to the power decomposition in Xpower, the power consumption 
%of an FPGA design includes signal power, clock power, BRAM power and so on. 
%To simplify the power model of the SCGRA overlay based FPGA accelerator, 
%we divide the power consumption into BRAM power and base system 
%power which essentially includes the power consumption of the rest part of the system. 
%As shown in \figref{fig:SCGRA-Power}, the base system power exhibits good linearity 
%over the SCGRA overlay size while the BRAM power is near linear to 
%the BRAM overhead. Therefore, both of them can be easily estimated with linear models. 
%
%\begin{figure}[tb]
%    \subfloat[\label{fig:Base-Power}]{%
%      \includegraphics[width=0.22\textwidth]{Base-Power}
%    }
%    \subfloat[\label{fig:BRAM-Power}]{%
%      \includegraphics[width=0.22\textwidth]{BRAM-Power}
%    }
%    \caption{Power consumption of the SCGRA overlay based FPGA accelerator, 
%    (a) Base system power including DSP power, clock power, etc., (b) BRAM power}
%    \label{fig:SCGRA-Power}
%\end{figure}
%
\subsection{Customization time}
\figref{fig:DSE-Time} shows the customization time of both the proposed two step (TS) customization
and an exhaustive search based customization (ES). TS typically completes the customization in 10
minutes to 20 minutes and it is around 100x faster than the ES on average. In particular, ES is extremely slow on MM which has three levels of loop with relatively large 
loop count and thus larger design space. Though TS also needs longer time to complete the
customization, it skips most of the unfeasible configurations and the runtime is 
less sensitive to the size of the design space. 

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.35\textwidth]{DSE-Time}
    \caption{Benchmark customization time using both TS and ES}
    \label{fig:DSE-Time}
\end{figure}

%\begin{table}[tb]
%    \small
%    \centering
%    \caption{Time Cost for RA DSE and ES DSE\label{tab:dsetime}}{
%        \begin{tabular}{l|l|l|l|l}
%            \hline
%            Benchmark & MM & FIR & KM & SE \\ \hline
%            RA DSE (min) & 20.2 & 10.6 & 13.4 & 11.4\\ \hline
%            ES DSE (min) & 2880.6 & 835.2 & 1140.5 & 946.2\\ \hline
%            Speedup & 142.6 & 78.8 & 85.1 & 86.2 \\ \hline
%        \end{tabular}
%    }
%\end{table}

\subsection{Customized accelerator performance}
In order to demonstrate the quality of proposed framework, we compared the performance of the
customized accelerators to that of an ARM processor on Zedboard. As shown in \figref{fig:DSE}, the
customized accelerators achieve up to 10X speedup over the ARM processor on the benchmark. For FIR, SE
and KM, the speedup is promising. MM has relatively low compute-IO rate and the single input and
output between the on-chip buffer and the SCGRA overlay limits the performance of the accelerator.
This problem can hopefully be alleviated by appropriate on-chip buffer partition, which will be
supported in the proposed framework in future.
\begin{figure}[tb]
    \centering
    \includegraphics[width=0.35\textwidth]{perf-cp}
    \caption{Customized FPGA loop accelerator performance}
    \label{fig:DSE}
\end{figure}


%\subsubsection{Design Tools Comparison}
%The proposed design framework will not be as useful if the performance of the 
%generated system is not at least on par with similar systems created with 
%conventional HLS tools. For that, we further implemented the 
%benchmarks using Vivado HLS with moderate effort. The loops in the benchmark 
%were unrolled as much as possible and the input/output buffers were set as large 
%as possible. The accelerators generated using HLS run at 100MHz, the accelerators 
%built on top of SCGRA overlay have the computation array running at 200MHz 
%and the communication fabrics running at 100MHz. Then the accelerators 
%generated using both tools were compared. 
%Since similar comparison has already been done in previous work \cite{scgra}, 
%we just brief the performance comparison for a quick reference.
%
%\begin{figure}[tb]
%	\subfloat[MM]{%
%		\includegraphics[width=0.22\textwidth]{mm-hls-cp}
%	}
%	\subfloat[FIR]{%
%		\includegraphics[width=0.22\textwidth]{fir-hls-cp}
%	}
%    \hfill
%	\subfloat[SE]{%
%		\includegraphics[width=0.22\textwidth]{se-hls-cp}
%	}
%	\subfloat[KM]{%
%		\includegraphics[width=0.22\textwidth]{km-hls-cp}
%	}
%    \caption{Performance comparison between the implementations 
%        using HLS and the proposed automatic customization framework.
%    All the run time is normalized to that of the HLS based implementations.}
%	\label{fig:hls-cp}
%\end{figure}
%
%
%\figref{fig:hls-cp} shows the performance comparison of the implementations using 
%both design tools. The proposed customization framework utilizes 
%SCGRA overlay as the backbone and it can't afford large 
%BRAM blocks for input/output buffers. As a result, the communication time is larger 
%especially when there is a lot of data reuse between consecutive data transmissions.
%For instance, HLS based design for MM can afford a 32k-word input buffer storing all 
%the input data. However, the SCGRA overlay based design can only 
%provide a 4k-word input buffer and it needs to transmit the same data 
%multiple times to complete the matrix multiplication (Note that it is 
%possible to partly reuse data transmissions of different groups, but it is 
%not supported in the experiments). Direct HLS can't support large 
%loop unrolling due to the DSP resource constrain. SCGRA overlay based accelerator 
%has a lot of distributed intermediate buffers and can accommodate larger loop unrolling.
%Therefore, the accelerators generated using the proposed framework provides competitive 
%pure computation time and overall performance especially for compute intensive loops.
%

